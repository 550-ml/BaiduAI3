{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "from paddle.vision.datasets import MNIST,Cifar10\n",
    "from paddle.io import Dataset\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = MNIST(mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_num_images(num):\n",
    "    if num < 1:\n",
    "        print('INFO:The number of input pictures must be greater than zero!')\n",
    "    else:\n",
    "        choose_list = []\n",
    "        for i in range(num):\n",
    "            choose_n = np.random.randint(len(mnist))\n",
    "            choose_list.append(choose_n)\n",
    "        fig = plt.gcf()\n",
    "        fig.set_size_inches(15, 17)\n",
    "        for i in range(num):\n",
    "            ax_img = plt.subplot(math.ceil(num / 2), 5, i + 1)\n",
    "            plt_img = mnist[choose_list[i]][0]\n",
    "            ax_img.imshow(plt_img, cmap='binary')\n",
    "            ax_img.set_title(str(mnist[choose_list[i]][1].item()),\n",
    "                             fontsize=20)\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLkAAAIhCAYAAACi3mjZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAA9hAAAPYQGoP6dpAABpYElEQVR4nO3deXhU9f3+/3tISFgTDIEEJCwuLBXBiogIIggScWXRqmgFatXaQAWsWOoCLjUiihSL8KkLEQURKoEKikuEgMpSIvwQBQRFQCVh0SwESCA5vz/4MhLJ+ySZzGTmnTwf1zXXlcw958zLE25PeHNmxuM4jiMAAAAAAADAYrWCPQAAAAAAAABQWSxyAQAAAAAAwHoscgEAAAAAAMB6LHIBAAAAAADAeixyAQAAAAAAwHoscgEAAAAAAMB6LHIBAAAAAADAeixyAQAAAAAAwHoscgEAAAAAAMB6LHIBAAAAAADAeixyoVwefPBBeTwe723FihXBHgnAr/Tu3btET8tzo8tA6Ni3b5+WLFmiRx99VAMGDFBsbKy3q8OHDw/2eADK4ejRo3rxxRfVt29fNWnSRBEREWrevLmuvvpqzZs3L9jjAShDYWGhXn75ZSUmJqpZs2aKjIxUgwYN1K5dO40YMUKfffZZsEdEGcKDPQBC38aNGzVlypRgjwHAz2rVqqVzzz032GMA+H/i4uKCPQKASti2bZtuuOEGbdu2rcT9e/fu1d69e/Xee+9p1qxZevvtt9WgQYMgTQnAZNeuXbrmmmv05Zdflri/sLBQX3/9tb7++mulpKRo1KhR+uc//ymPxxOkSeGGRS64Ki4u1t13363jx4+radOm2rdvX7BHAmAwa9Ys5efnuz7mq6++0s033yxJ6tu3r84888yqGA1ABbVs2VLt27fXBx98EOxRAJTDvn37dOWVV2rPnj2SpJtuuknDhg1T8+bN9eOPP+q1117TggUL9MEHH+iWW27RkiVLgjwxgFMdO3asxAJXp06dNHbsWLVr1055eXn65JNP9Nxzzyk/P18vvPCCmjdvrr/97W9BnhqlYZELrqZNm6b//e9/at++vQYNGqTk5ORgjwTAoE2bNmU+5vXXX/d+fccddwRyHAAV9Oijj6pr167q2rWr4uLi9N1335Wr1wCC7/HHH/cucE2YMEETJ070Zr/97W91zTXXaMKECXr88ce1dOlS/ec//9GNN94YpGkB/NrixYu9C1zdu3fXqlWrFBYW5s2vvPJKXX/99erevbuOHTumSZMm6a9//avCw1lSCTW8JxeMdu/erUceeUSSNHPmTEVERAR5IgCVUVxcrDlz5kiSGjRooMGDBwd5IgCneuyxx3TttdfyskXAMkVFRXrjjTckSa1atfL+/vxrjz76qFq2bClJevrpp6tsPgBlO/W9tsaPH19igeukLl266Nprr5UkZWdna8uWLVU2H8qPRS4YJSUl6dChQxo2bJguv/zyYI8DoJLS0tL0ww8/SJJuvPFG1atXL8gTAQBgv+3btysnJ0fSias9SvvLsSSFhYXpyiuvlCRlZGRo586dVTYjAHeFhYXer8866yzj484+++xSt0HoYJELpZo/f76WLFmimJgYPfvss8EeB4AfzJ492/s1L1UEAMA/Dh486P26rCsxT81XrVoVsJkAVEy7du28X3/77bfGx33zzTeSJI/Hwwc4hSgWuXCa7Oxs3XfffZKkSZMmKTY2NsgTAaisQ4cOKTU1VdKJl1L07t07uAMBAFBNnPpJiSev6DI5Nf/qq68CNhOAirn11lsVFRUl6cTfgYuKik57zIYNG7R06VJJ0tChQ72PR2hhkQunGTdunDIzM9WjRw/deeedwR4HgB+8/fbb3k9evP322/nIYwAA/OScc85R7dq1JUkrV650feyp+e7duwM6F4Dyi42N1euvv6569erp008/VdeuXTV79mytWbNGH330kR577DFdfvnlKiws1IUXXqjnnnsu2CPDgEUulLBq1Sq9/PLLCg8P18yZM/mLMFBN8FJFAAACo379+rriiiskSZs2bdKbb75Z6uPefPNNffHFF97v8/LyqmQ+AOVz/fXXKyMjQ3/84x+1ceNGDRs2TN27d9eVV16piRMnql69epo6dapWrVrFh8SEMBa54FVYWKi7775bjuNozJgx6tixY7BHAuAH33//vVasWCFJuuSSS9S2bdvgDgQAQDUzceJEhYeHS5KGDRumJ598Urt379axY8e0e/duPfnkkxo2bFiJTys/cuRIsMYFUIrCwkLNnj1bixcvluM4p+VZWVl644039NFHHwVhOpQXi1zweuqpp7R161a1bNlSEyZMCPY4APzkjTfeUHFxsaQTv3gDAAD/uuSSS/R///d/Cg8P17Fjx/TII4+oVatWioiIUKtWrfTII48oPDxcU6ZM8W7TsGHDIE4M4FT5+fnq16+fkpOT9dNPP2ncuHHasmWLCgoKlJOTow8++EA9e/bU+vXrNXDgwBJdRmhhkQuSpK1btyo5OVmS9MILL6h+/fpBngiAv7z++uuSpMjISN18881BngYAgOrpD3/4g9auXatBgwaV+F06PDxc119/vT7//HNddNFF3vvPOOOMYIwJoBQTJ070fuLpK6+8okmTJql9+/aKiIhQVFSUrrzySi1fvlx9+vSR4zh64IEH9P/9f/9fkKdGacKDPQBCw/PPP6/CwkKdddZZOnz4sObNm3faYzZv3uz9+uOPP1ZmZqYk6brrrmNRDAhR69ev935607XXXssv1AAABNCFF16ohQsX6vjx49q7d68KCwt15plnqk6dOpJOXF190nnnnResMQGcwnEcvfrqq5Kktm3bGl/5EB4erieeeEI9e/ZUcXGxUlJS9Pzzz1flqCgHFrkgSSooKJAkffvtt7r11lvLfPwTTzzh/Xrnzp0scgEh6tQ3nOeligAAVI3w8HAlJCScdn9GRob364svvrgqRwJgkJWVpZ9++kmS9Nvf/tb1sV26dPF+vXXr1oDOBd/wckUAqKaOHTvmvSqzSZMmGjBgQJAnAgCg5ioqKtLChQslSQkJCbr00kuDPBEASd4PjZCk48ePuz722LFjpW6H0MEiFyRJKSkpchzH9Xbqm9EvX77ce3/r1q2DNzgAo/fee0/79++XJA0dOpQTMQAAQfTKK69o9+7dkqR77rlHYWFhQZ4IgCTFxMQoKipKkrR69WrXha709HTv123atAn4bKg4FrkAoJo69aWKd9xxRxAnAQCg+vvhhx+M2ccff6zRo0dLOvGeP/fff38VTQWgLLVq1dI111wjSfrxxx/1j3/8o9TH/fzzz3rwwQe931977bVVMh8qhn/WB4Bq6Oeff9aSJUskSR07dtSFF14Y5IkAlOWTTz7Rjh07vN8fOHDA+/WOHTuUkpJS4vHDhw+voskAlEfHjh11+eWX65prrtF5552nyMhI7d69W6mpqZozZ46Ki4sVExOj+fPne9+IHkBoePTRR7V48WIdPnxYEydOVEZGhoYNG6azzjpLR48e1Zo1azR16lTv1Zh9+/ZV//79gzw1SsMiFwBUQ2+99Zb3AyW4iguww8svv6zXXnut1OzTTz/Vp59+WuI+FrmA0HLs2DEtXrxYixcvLjU/77zzNGfOHHXu3LmKJwNQlvbt22vx4sW69dZbdeDAAb3zzjt65513Sn3sFVdcoQULFlTxhCgvFrkAoBp6/fXXJUlhYWG67bbbgjwNAADV38svv6wPPvhA69at0969e3Xo0CE1adJEnTp10k033aTbb79dtWvXDvaYAAz69eunrVu36pVXXtF7772nL7/8UtnZ2QoPD1d8fLy6du2qoUOH6vrrr5fH4wn2uDDwOI7jBHsIAAAAAAAAoDJ443kAAAAAAABYj0UuAAAAAAAAWI9FLgAAAAAAAFiPRS4AAAAAAABYj0UuAAAAAAAAWI9FLgAAAAAAAFgvPFA7nj59uiZPnqzMzEx17txZL7zwgi6++OIytysuLtaPP/6ohg0byuPxBGo8wFqO4ygvL0/NmzdXrVqBWaf2tb8SHQbcVEV/Jc7BQKBwDgbsxTkYsFu5O+wEwLx585yIiAjn1Vdfdb788kvnrrvucho1auRkZWWVue2ePXscSdy4cSvjtmfPnkDUt1L9pcPcuJXvFqj+VrbD9Jcbt/LdOAdz42bvjXMwN25238rqsMdxHEd+1q1bN3Xt2lX/+te/JJ1YlU5ISNCoUaP0t7/9zXXbnJwcNWrUSHv27FFUVJS/RwOsl5ubq4SEBGVnZys6Otrv+69MfyU6DLgJdH8lzsFAIHEOBuzFORiwW3k77PeXKxYWFiojI0Pjx4/33lerVi3169dPq1evLnP7k5dmRkVFUW7ARSAuY65sf0+diw4DZoF6GQLnYKBqcA4G7MU5GLBbWR32+yLXgQMHVFRUpLi4uBL3x8XFaevWrac9vqCgQAUFBd7vc3Nz/T0SgHKqaH8lOgyEEs7BgL04BwN24xwMhIagf7picnKyoqOjvbeEhIRgjwSgAugwYC/6C9iNDgP2or9AYPh9kSs2NlZhYWHKysoqcX9WVpbi4+NPe/z48eOVk5Pjve3Zs8ffIwEop4r2V6LDQCjhHAzYi3MwYDfOwUBo8PsiV0REhLp06aK0tDTvfcXFxUpLS1P37t1Pe3xkZKT3dce8/hgIror2V6LDQCjhHAzYi3MwYDfOwUBo8Pt7cknS2LFjNWzYMF100UW6+OKLNXXqVOXn52vEiBGBeDoAfkR/AbvRYcBe9BewGx0Ggi8gi1w333yz9u/fr0cffVSZmZm64IILtGzZstPehA9A6KG/gN3oMGAv+gvYjQ4DwedxHMcJ9hCnys3NVXR0tHJycrhkEyhFqHck1OcDginU+xHq8wHBFuodCfX5gGAK9X6E+nxAsJW3I0H/dEUAAAAAAACgsljkAgAAAAAAgPVY5AIAAAAAAID1WOQCAAAAAACA9VjkAgAAAAAAgPVY5AIAAAAAAID1WOQCAAAAAACA9VjkAgAAAAAAgPVY5AIAAAAAAID1WOQCAAAAAACA9VjkAgAAAAAAgPVY5AIAAAAAAID1WOQCAAAAAACA9VjkAgAAAAAAgPVY5AIAAAAAAID1WOQCAAAAAACA9VjkAgAAAAAAgPVY5AIAAAAAAID1woM9AFCaoUOHGrO3337bddv//e9/xqxTp04+zwQAQFV7+umnXfMpU6YYs3379vl7HAAAAmr06NHGbOnSpcbsD3/4gzEbMmSIMWvbtm255oI9uJILAAAAAAAA1mORCwAAAAAAANZjkQsAAAAAAADWY5ELAAAAAAAA1mORCwAAAAAAANZjkQsAAAAAAADWC/f3DidOnKjHHnusxH3t2rXT1q1b/f1UsNzPP/9szNLS0oxZYWGh634///xzY9apU6eyB6vB6C9gNzpc/aSmprrmHo+niiZBoNFfwG50uHz+8pe/uOYzZswwZkVFRcbsoYceMmZPPPGEMWvcuLExe/DBB42ZJHXv3t2YdenSxXVbBI7fF7kk6bzzztNHH330y5OEB+RpAAQA/QXsRocBe9FfwG50GAi+gLQuPDxc8fHxgdg1gACjv4Dd6DBgL/oL2I0OA8EXkPfk2r59u5o3b66zzjpLt912m3bv3m18bEFBgXJzc0vcAARPRfor0WEg1HAOBuzFORiwG+dgIPj8vsjVrVs3paSkaNmyZZoxY4Z27typyy67THl5eaU+Pjk5WdHR0d5bQkKCv0cCUE4V7a9Eh4FQwjkYsBfnYMBunIOB0OBxHMcJ5BNkZ2erVatWmjJliu68887T8oKCAhUUFHi/z83NVUJCgnJychQVFRXI0RBkbm883759e2O2b98+1/3OmjXLmA0fPrzMuUJdbm6uoqOjq6QjZfVXosNARVRlfyXOwdVBt27dXPPvvvvOmGVlZfl5GnAOBuzFOTg0BOqN593UqVPHmPHG8/Yob4cD/k54jRo1Utu2bbVjx45S88jISEVGRgZ6DAA+KKu/Eh0GQhnnYMBenIMBu3EOBoIj4Itchw4d0jfffKPf//73gX4qWGbFihXGzO1qrfr167vut23btr6OhF+hv4Dd6LD91q1b55o3bdq0iiZBVaO/gbFkyRJjtnDhQmO2YMECY3bo0CFjVtYVOQMGDDBm/fr1M2aDBw82ZjExMa7PiapBh0tX1t/VfL1ay83Ro0eN2Q8//GDMyrrq7KmnnjJmXMkVPH5/T66//vWvSk9P13fffafPPvtMgwYNUlhYmG699VZ/PxUAP6O/gN3oMGAv+gvYjQ4DocHvV3J9//33uvXWW3Xw4EE1adJEPXv21Jo1a9SkSRN/PxUAP6O/gN3oMGAv+gvYjQ4DocHvi1zz5s3z9y4BVBH6C9iNDgP2or+A3egwEBr8/nJFAAAAAAAAoKqxyAUAAAAAAADrscgFAAAAAAAA6/n9PbmA8vruu+982i4hIcE1v/TSS33aL6qvlStXGrO5c+cas0GDBhmzCy+80PU5a8KbjO7fv9+YvfHGG8bs6aefdt3vvn37jFmHDh2M2VdffeW6XwBA9fDhhx+65s8995wx++CDD4yZ4zg+zdOvXz9jtm7dOtdt33rrLZ+yGTNmGDO3/8bGjRu7zgME2u9//3vX/PnnnzdmO3fuNGY9e/Y0ZmPGjDFmZ555pjEr63fWtm3buuYIDq7kAgAAAAAAgPVY5AIAAAAAAID1WOQCAAAAAACA9VjkAgAAAAAAgPVY5AIAAAAAAID1WOQCAAAAAACA9cKDPQBKN3z4cGN2+PBhYzZ79mxjVqdOncqMFDL69OkT7BFgmUWLFhmzf//738bspZdeMmYtW7Z0fc7Y2Ngy57LdgQMHjNmuXbuMmcfjcd2vW75t2zZjtnDhQmM2ePBg1+cEANhj6NChrrnb+em2224zZtOmTTNm9erVM2YRERHG7NixY8ZMkhYsWGDMXn31VWO2fPlyY9a/f39j9tprr7nO07FjR9ccqKzo6GjX3K1Pbm6//XZjNmjQIJ/26fa7ZSjasWOHT9udc845fp4kuLiSCwAAAAAAANZjkQsAAAAAAADWY5ELAAAAAAAA1mORCwAAAAAAANZjkQsAAAAAAADWY5ELAAAAAAAA1mORCwAAAAAAANYLD/YAKN27775rzGJiYoxZcXFxIMYBrNa+fXtj5jiOT/v87rvvXPNdu3b59Jwej6dKtwvWc7rxddsDBw74/JxAMGVlZfm8bWW6BoSySZMmGbODBw+6bjt69Gif9hsREVHmXBUVGRnpmt9+++3GbOjQocbsv//9rzGbMmWKT88nSWlpacascePGrtsC/pCQkGDMtm3bZsxeeOEFY3bTTTcZszPOOKN8g/nR+vXrfcrefvtt1/3u2LHDp3m6d+9uzKZNm2bMYmNjfXq+QONKLgAAAAAAAFiPRS4AAAAAAABYj0UuAAAAAAAAWI9FLgAAAAAAAFiPRS4AAAAAAABYj0UuAAAAAAAAWC+8ohusXLlSkydPVkZGhvbu3avU1FQNHDjQmzuOowkTJuill15Sdna2evTooRkzZujcc8/159w1mttHp3744YfG7IYbbgjEOD7buHFjsEeocejv6Twej09ZZfYbStsF4zkDNevgwYN93q8t6HD1tHTpUp+3vfHGG/04CQKJ/lbMZ599ZswaNWrkuu348eONWUREhK8jVblatczXI5z6Z+fXWrRoYcx+//vfuz7n4sWLjdkf/vAH122rOzpcNVJSUoxZnz59jNmXX35pzP7zn/8Ys7vuusuYZWZmGjNJmjdvnjFLT083Zu+++64xO3bsmDGLiopynefyyy83ZiNGjHDd1uTIkSM+bRdMFb6SKz8/X507d9b06dNLzZ955hlNmzZNM2fO1Nq1a1W/fn0lJibq6NGjlR4WQOXQX8BudBiwF/0F7EaHATtU+EquAQMGaMCAAaVmjuNo6tSpevjhh71XDc2ePVtxcXFatGiRbrnllspNC6BS6C9gNzoM2Iv+Anajw4Ad/PqeXDt37lRmZqb69evnvS86OlrdunXT6tWrS92moKBAubm5JW4Aqp4v/ZXoMBAqOAcD9uIcDNiNczAQOvy6yHXyNatxcXEl7o+LizO+njU5OVnR0dHeW0JCgj9HAlBOvvRXosNAqOAcDNiLczBgN87BQOgI+qcrjh8/Xjk5Od7bnj17gj0SgAqgw4C96C9gNzoM2Iv+AoHh10Wu+Ph4SVJWVlaJ+7OysrzZr0VGRioqKqrEDUDV86W/Eh0GQgXnYMBenIMBu3EOBkJHhd943k2bNm0UHx+vtLQ0XXDBBZKk3NxcrV27Vvfee68/nwoGX3/9dbBHKDebZq0Jamp/HccxZoMGDTJm9erVc93v1q1bfZ7J3y677DKft23fvr1P2y1btsyYLVq0yHVbt5/JQw89ZMxiY2PLnKs6q6kdruk6duwY7BHgB/T3dMuXLzdmF110keu2TZs29fc4VnE7Pp9//rnrtmFhYf4ep0agw/7TvHlzY/bHP/7RmD344IPGbNy4ccasbt26xuwf//iHMZOkbdu2GTO332c9Ho8xu+aaa4zZ/fff7zpP7969XfOaosKLXIcOHdKOHTu83+/cuVMbN25UTEyMWrZsqdGjR+vJJ5/UueeeqzZt2uiRRx5R8+bNNXDgQH/ODcAH9BewGx0G7EV/AbvRYcAOFV7kWr9+vfr06eP9fuzYsZKkYcOGKSUlRePGjVN+fr7uvvtuZWdnq2fPnlq2bJnq1Knjv6kB+IT+Anajw4C96C9gNzoM2KHCi1y9e/cu89K7xx9/XI8//nilBgPgf/QXsBsdBuxFfwG70WHADkH/dEUAAAAAAACgsljkAgAAAAAAgPVY5AIAAAAAAID1KvyeXECwXX311cEeAdWI20f4PvTQQ8bswgsvDMQ41caf/vQnY+Z2zCWpSZMmxuyuu+7yeSagOurbt2+wRwAC4re//a0x69mzZxVOYp/JkycbsxdffNF122XLlhmzdu3a+TwT4A+33HKLMZszZ44x27RpkzG74447KjWTSVRUlDG79NJLjdm8efOMWf369Ss1U03BlVwAAAAAAACwHotcAAAAAAAAsB6LXAAAAAAAALAei1wAAAAAAACwHotcAAAAAAAAsB6LXAAAAAAAALBeeLAHqKnWrFnjmv/8888+7Xf9+vXGbP/+/casSZMmPj1fWbZs2WLMNm7c6NM++ehU+JPjOMZs7NixxmzFihUBmMYuTz75pDFzO65lmTFjhjFr2bKlz/sFQtX27duDPQIQctq2bWvMZs+e7brtuHHjjFmDBg18nimULF682Ji98MILxiwzM9N1v9nZ2b6OBARcQkKCMXv33XeNWWJiojH78ssvfZ7nqquu8mkeBBZXcgEAAAAAAMB6LHIBAAAAAADAeixyAQAAAAAAwHoscgEAAAAAAMB6LHIBAAAAAADAeixyAQAAAAAAwHrhwR6gpirr44vDw80/muPHjxuz+fPnG7P09HRjdscddxizG2+80ZhJUlRUlDF7/PHHjdnRo0eNWf369Y1Z69atXecBfm3w4MHG7E9/+pMx69ChQyDGscqWLVuM2aRJk4yZx+PxKZPcf15AdbRq1Spjdu6557puGx8f7+9xgJC3a9cu13zt2rXGrG/fvv4eJ2DmzZtnzEaMGGHM3H7HPuuss1yfs1u3bmUPBoSg5s2bG7NzzjnHmG3evNnn57zssst83haBw5VcAAAAAAAAsB6LXAAAAAAAALAei1wAAAAAAACwHotcAAAAAAAAsB6LXAAAAAAAALAei1wAAAAAAACwHotcAAAAAAAAsF54RTdYuXKlJk+erIyMDO3du1epqakaOHCgNx8+fLhee+21EtskJiZq2bJllR62OpkzZ45rfvToUb8/Z1ZWljGbPHmyT1mgXHTRRcasTZs2VThJ9VJT+xsbG2vMHMfxabuawu1nn5+fb8zcjuvs2bMrNVNNVlM7XN15PB5jFhcX57ptdHS0v8dBgNDfihk5cqQxK+v36LVr1xqzvn37+jyTLwoKClzzUaNGGbPXX3/dmPXp08eYbdmyxZglJia6zgMzOhza1q9fb8zeffddY+Z2Di7L448/bsx69+5tzLp37+7zc6JsFb6SKz8/X507d9b06dONj7nqqqu0d+9e7+3NN9+s1JAA/IP+Anajw4C96C9gNzoM2KHCV3INGDBAAwYMcH1MZGSk4uPjfR4KQGDQX8BudBiwF/0F7EaHATsE5D25VqxYoaZNm6pdu3a69957dfDgQeNjCwoKlJubW+IGIHgq0l+JDgOhhnMwYC/OwYDdOAcDwef3Ra6rrrpKs2fPVlpamiZNmqT09HQNGDBARUVFpT4+OTlZ0dHR3ltCQoK/RwJQThXtr0SHgVDCORiwF+dgwG6cg4HQUOGXK5bllltu8X59/vnnq1OnTjr77LO1YsWKUt/ocfz48Ro7dqz3+9zcXAoOBElF+yvRYSCUcA4G7MU5GLAb52AgNATk5YqnOuussxQbG6sdO3aUmkdGRioqKqrEDUBoKKu/Eh0GQhnnYMBenIMBu3EOBoLD71dy/dr333+vgwcPqlmzZoF+qpBz5MgRYzZv3jyf9/vvf//bmLVu3dqYffTRR8bM7WNV8/LyyjVXaTIzM42Z20cqd+rUyefnhP/UhP66faxzhw4dqnCS4Fm4cKExe/rpp42Zrx+5/Jvf/Man7VBxNaHDtvj++++N2datW41Z+/btAzEOLFDT+9u5c2djdscdd7hu+9RTTxmzLVu2GLNTr6r5tXr16hmzL774wpjNnTvXmEnSqlWrjNnkyZON2eWXX27Munfv7vqcqBo1vcNVrbi42JgdO3bMmNWvX9+Y3XDDDa7P6dbvxMREY/bcc88Zs9tuu82Yuf1/CL+o8CLXoUOHSqxG79y5Uxs3blRMTIxiYmL02GOPaciQIYqPj9c333yjcePG6ZxzznH9IQOoGvQXsBsdBuxFfwG70WHADhVe5Fq/fr369Onj/f7kv3gMGzZMM2bM0KZNm/Taa68pOztbzZs3V//+/fXEE08oMjLSf1MD8An9BexGhwF70V/AbnQYsEOFF7l69+4tx3GM+fvvv1+pgQAEDv0F7EaHAXvRX8BudBiwQ8DfeB4AAAAAAAAINBa5AAAAAAAAYD0WuQAAAAAAAGC9Cr8nF8pv0qRJxuy7775z3fZ3v/udMRs2bJgxi4iIMGZXXnmlMXObtTIGDx5szFJTUwPynEBF1IRPvMnPz3fNH374YWO2b98+Y+bxeIyZ23G98MILXecBqqMVK1YYs4MHD1bdIEA18Oyzz7rmmzdvNmZvvPGGT5mvWrdu7ZrPmTPHmPXv39+YPf/888bM7bzvtk+gJjrjjDOM2Wuvvea67SOPPGLMxo8fb8xGjhxpzNLS0ozZSy+95DpPw4YNXfOagiu5AAAAAAAAYD0WuQAAAAAAAGA9FrkAAAAAAABgPRa5AAAAAAAAYD0WuQAAAAAAAGA9FrkAAAAAAABgvfBgD1Cd3Xfffcbsq6++ct326aefNmYRERE+z1TV9uzZE+wRgBovOTnZNd+2bZsx83g8PmWvv/562YMBNcjmzZuDPQJQbTRo0MA1nzt3rjF79dVXjdmRI0d8nslk+PDhrnmHDh182m9+fr4xCw83/xUvLi7Op+cDaqKwsDDXvF27dsZs4cKFxuxf//qXMXvggQeMWa1a7tcozZw505hFRUW5bludcCUXAAAAAAAArMciFwAAAAAAAKzHIhcAAAAAAACsxyIXAAAAAAAArMciFwAAAAAAAKzHIhcAAAAAAACsZ/58WVTaGWecYczmz59fhZME1o8//mjMtm3b5tM+L730Ul/HAWqk/fv3G7O3337bdVvHcXzKBg0aZMxiY2NdnxOoaXztmVsGoHQtW7Y0ZhMnTqy6QSrp+PHjxiw1NdWYtWjRwph17969UjMB1Y3b79CLFy923faGG27w6TlHjhxpzObMmWPM5s2b57rfMWPGGLOuXbuWPVg1wZVcAAAAAAAAsB6LXAAAAAAAALAei1wAAAAAAACwHotcAAAAAAAAsB6LXAAAAAAAALAei1wAAAAAAACwHotcAAAAAAAAsF54RR6cnJyshQsXauvWrapbt64uvfRSTZo0Se3atfM+5ujRo7r//vs1b948FRQUKDExUS+++KLi4uL8PjxCQ25urjHLy8vzaZ/h4RX6o4lyosPV1x133GHMtm3b5rqtx+MxZu3btzdmr7/+etmDwW/or92++OILY+bWwU6dOgViHAQBHUZF/fDDD8bs888/N2ajRo0KxDg1Gv2tvgoKCoxZcnKy67Y9e/Y0Zo0bN/ZpnnvvvdeYrV271qd91jQVupIrPT1dSUlJWrNmjT788EMdO3ZM/fv3V35+vvcxY8aM0TvvvKMFCxYoPT1dP/74owYPHuz3wQFUHB0G7EV/AbvRYcBe9BewR4Uul1m2bFmJ71NSUtS0aVNlZGSoV69eysnJ0SuvvKK5c+fqiiuukCTNmjVLHTp00Jo1a3TJJZf4b3IAFUaHAXvRX8BudBiwF/0F7FGp9+TKycmRJMXExEiSMjIydOzYMfXr18/7mPbt26tly5ZavXp1qfsoKChQbm5uiRuAqkGHAXvRX8BudBiwF/0FQpfPi1zFxcUaPXq0evTooY4dO0qSMjMzFRERoUaNGpV4bFxcnDIzM0vdT3JysqKjo723hIQEX0cCUAF0GLAX/QXsRocBe9FfILT5vMiVlJSkzZs3a968eZUaYPz48crJyfHe9uzZU6n9ASgfOgzYi/4CdqPDgL3oLxDafPoIu5EjR2rJkiVauXKlWrRo4b0/Pj5ehYWFys7OLrGKnZWVpfj4+FL3FRkZqcjISF/GAOAjOgzYi/4CdqPDgL3oLxD6KrTI5TiORo0apdTUVK1YsUJt2rQpkXfp0kW1a9dWWlqahgwZIunER9fv3r1b3bt399/UCCkLFy70abuTr2Evzck3bIR/0WG7ZWRkGDO3jxJ3HMfn5xw9erQxq1evns/7RcXR39Dn9tHey5cvN2atWrUyZn/7298qNRNCBx0G7EV/Q99ZZ51lzLp06WLM3H6/Xrdunetz9u/f35glJSUZs8TERGNWmSsE33//fWPWtWtXn/drmwotciUlJWnu3LlavHixGjZs6H19cXR0tOrWravo6GjdeeedGjt2rGJiYhQVFaVRo0ape/fufKIEEALoMGAv+gvYjQ4D9qK/gD0qtMg1Y8YMSVLv3r1L3D9r1iwNHz5ckvT888+rVq1aGjJkiAoKCpSYmKgXX3zRL8MCqBw6DNiL/gJ2o8OAvegvYI8Kv1yxLHXq1NH06dM1ffp0n4cCEBh0GLAX/QXsRocBe9FfwB4+f7oiAAAAAAAAECpY5AIAAAAAAID1WOQCAAAAAACA9Sr0nlyAP9WtW9eYxcTEVOEkgB2uvvpqY3bgwAFj5vF4XPf7m9/8xpgNHjy47MEASJIOHTpkzIqKioxZv379jFnLli0rNRMAe3377bfBHgGwRmxsrDEbOXKkMfvLX/5izPLy8lyfc8OGDcbszjvvNGZl/W5uUrt2bdfc7e8KNQlXcgEAAAAAAMB6LHIBAAAAAADAeixyAQAAAAAAwHoscgEAAAAAAMB6LHIBAAAAAADAeixyAQAAAAAAwHrhwR4A9ktMTDRmzz77rDHr0aNHIMYBrLZy5Upjtm/fPmPm9lHEjuO4Pudll11mzNw+jhlASX379jVmjRo1MmbXXHNNAKYBYLv169f7tJ3beR2oiYYNG2bMBg8ebMymT5/uut8PPvjAmC1fvrzswSqorN8XLrzwQr8/p424kgsAAAAAAADWY5ELAAAAAAAA1mORCwAAAAAAANZjkQsAAAAAAADWY5ELAAAAAAAA1mORCwAAAAAAANYLD/YAsF+XLl2M2U8//VSFkwB22L9/vzG7//77jZnH4/Ep69Wrl+s8d911l2sOoPL27dsX7BEAVCNu5/1mzZpV4SSA3Ro2bGjM/va3v7luW1aO4OBKLgAAAAAAAFiPRS4AAAAAAABYj0UuAAAAAAAAWI9FLgAAAAAAAFiPRS4AAAAAAABYj0UuAAAAAAAAWC+8Ig9OTk7WwoULtXXrVtWtW1eXXnqpJk2apHbt2nkf07t3b6Wnp5fY7p577tHMmTP9MzEAn9Hh0LB7925jlpGRYcwcx/Hp+f7yl7+45hdeeKFP+0XVor+A3egwKurUPxu/ds011xiznj17BmKcGo3+Avao0JVc6enpSkpK0po1a/Thhx/q2LFj6t+/v/Lz80s87q677tLevXu9t2eeecavQwPwDR0G7EV/AbvRYcBe9BewR4Wu5Fq2bFmJ71NSUtS0aVNlZGSoV69e3vvr1aun+Ph4/0wIwG/oMGAv+gvYjQ4D9qK/gD0q9Z5cOTk5kqSYmJgS98+ZM0exsbHq2LGjxo8fr8OHD1fmaQAECB0G7EV/AbvRYcBe9BcIXRW6kutUxcXFGj16tHr06KGOHTt67x86dKhatWql5s2ba9OmTXrwwQe1bds2LVy4sNT9FBQUqKCgwPt9bm6uryMBqAA6DNiL/gJ2o8OAvegvENp8XuRKSkrS5s2b9cknn5S4/+677/Z+ff7556tZs2bq27evvvnmG5199tmn7Sc5OVmPPfaYr2MA8BEdBuxFfwG70WHAXvQXCG0+vVxx5MiRWrJkiZYvX64WLVq4PrZbt26SpB07dpSajx8/Xjk5Od7bnj17fBkJQAXQYcBe9BewGx0G7EV/gdBXoSu5HMfRqFGjlJqaqhUrVqhNmzZlbrNx40ZJUrNmzUrNIyMjFRkZWZExAPiIDgP2or+A3egwYC/6C9ijQotcSUlJmjt3rhYvXqyGDRsqMzNTkhQdHa26devqm2++0dy5c3X11VercePG2rRpk8aMGaNevXqpU6dOAfkPAFB+dDg0xMbGGrNTP6Hn11auXGnMhgwZYswGDx5cvsEQ0ugvYDc6jIq6/vrrfcrgf/QXsEeFFrlmzJghSerdu3eJ+2fNmqXhw4crIiJCH330kaZOnar8/HwlJCRoyJAhevjhh/02MADf0WHAXvQXsBsdBuxFfwF7VPjlim4SEhKUnp5eqYEABA4dBuxFfwG70WHAXvQXsIdPbzwPAAAAAAAAhBIWuQAAAAAAAGA9FrkAAAAAAABgPRa5AAAAAAAAYL0KvfE8AKDyWrVqZcxWrFhRdYMAAAAAQDXClVwAAAAAAACwHotcAAAAAAAAsB6LXAAAAAAAALAei1wAAAAAAACwHotcAAAAAAAAsF7Ifbqi4ziSpNzc3CBPAoSmk9042ZVQQ4cBM/oL2I0OA/aiv4DdytvhkFvkysvLkyQlJCQEeRIgtOXl5Sk6OjrYY5yGDgNlo7+A3egwYC/6C9itrA57nBBbyi4uLtaPP/6ohg0byuPxKDc3VwkJCdqzZ4+ioqKCPV7I4fiYVddj4ziO8vLy1Lx5c9WqFXqvOD61w3l5edXyZ+Av1fXPqL9Ux+NjU385B5eN42NWXY+NTR3mHOyuuv4Z9ZfqeHxs6i/n4LJxfMyq67Epb4dD7kquWrVqqUWLFqfdHxUVVa1+QP7G8TGrjscmFP/16aRTO+zxeCRVz5+BP3F83FW342NLf09V3X4G/sbxMauOx8aWDnMOLh+Oj7vqdnxs6e+pqtvPwN84PmbV8diUp8Oht4QNAAAAAAAAVBCLXAAAAAAAALBeyC9yRUZGasKECYqMjAz2KCGJ42PGsQk+fgbuOD7uOD7Bx8/AHcfHjGMTfPwM3HF83HF8go+fgTuOj1lNPzYh98bzAAAAAAAAQEWF/JVcAAAAAAAAQFlY5AIAAAAAAID1WOQCAAAAAACA9VjkAgAAAAAAgPVCepFr+vTpat26terUqaNu3bpp3bp1wR4pKFauXKnrrrtOzZs3l8fj0aJFi0rkjuPo0UcfVbNmzVS3bl3169dP27dvD86wVSw5OVldu3ZVw4YN1bRpUw0cOFDbtm0r8ZijR48qKSlJjRs3VoMGDTRkyBBlZWUFaeKahQ6fQIfN6HDoor8n0F8z+hva6PAJdNiMDocu+nsC/TWjv2Yhu8j11ltvaezYsZowYYI+//xzde7cWYmJidq3b1+wR6ty+fn56ty5s6ZPn15q/swzz2jatGmaOXOm1q5dq/r16ysxMVFHjx6t4kmrXnp6upKSkrRmzRp9+OGHOnbsmPr376/8/HzvY8aMGaN33nlHCxYsUHp6un788UcNHjw4iFPXDHT4F3TYjA6HJvr7C/prRn9DFx3+BR02o8Ohif7+gv6a0V8XToi6+OKLnaSkJO/3RUVFTvPmzZ3k5OQgThV8kpzU1FTv98XFxU58fLwzefJk733Z2dlOZGSk8+abbwZhwuDat2+fI8lJT093HOfEsahdu7azYMEC72O2bNniSHJWr14drDFrBDpcOjrsjg6HBvpbOvrrjv6GDjpcOjrsjg6HBvpbOvrrjv7+IiSv5CosLFRGRob69evnva9WrVrq16+fVq9eHcTJQs/OnTuVmZlZ4lhFR0erW7duNfJY5eTkSJJiYmIkSRkZGTp27FiJ49O+fXu1bNmyRh6fqkKHy48Ol0SHg4/+lh/9LYn+hgY6XH50uCQ6HHz0t/zob0n09xchuch14MABFRUVKS4ursT9cXFxyszMDNJUoenk8eBYScXFxRo9erR69Oihjh07SjpxfCIiItSoUaMSj62Jx6cq0eHyo8O/oMOhgf6WH/39Bf0NHXS4/OjwL+hwaKC/5Ud/f0F/SwoP9gCAvyQlJWnz5s365JNPgj0KAB/QYcBe9BewGx0G7EV/SwrJK7liY2MVFhZ22jv/Z2VlKT4+PkhThaaTx6OmH6uRI0dqyZIlWr58uVq0aOG9Pz4+XoWFhcrOzi7x+Jp2fKoaHS4/OnwCHQ4d9Lf86O8J9De00OHyo8Mn0OHQQX/Lj/6eQH9PF5KLXBEREerSpYvS0tK89xUXFystLU3du3cP4mShp02bNoqPjy9xrHJzc7V27doacawcx9HIkSOVmpqqjz/+WG3atCmRd+nSRbVr1y5xfLZt26bdu3fXiOMTLHS4/OgwHQ419Lf86C/9DUV0uPzoMB0ONfS3/Ogv/TUK6tveu5g3b54TGRnppKSkOF999ZVz9913O40aNXIyMzODPVqVy8vLczZs2OBs2LDBkeRMmTLF2bBhg7Nr1y7HcRzn6aefdho1auQsXrzY2bRpk3PDDTc4bdq0cY4cORLkyQPv3nvvdaKjo50VK1Y4e/fu9d4OHz7sfcyf/vQnp2XLls7HH3/srF+/3unevbvTvXv3IE5dM9DhX9BhMzocmujvL+ivGf0NXXT4F3TYjA6HJvr7C/prRn/NQnaRy3Ec54UXXnBatmzpREREOBdffLGzZs2aYI8UFMuXL3cknXYbNmyY4zgnPj71kUceceLi4pzIyEinb9++zrZt24I7dBUp7bhIcmbNmuV9zJEjR5w///nPzhlnnOHUq1fPGTRokLN3797gDV2D0OET6LAZHQ5d9PcE+mtGf0MbHT6BDpvR4dBFf0+gv2b018zjOI7jn2vCAAAAAAAAgOAIyffkAgAAAAAAACqCRS4AAAAAAABYj0UuAAAAAAAAWI9FLgAAAAAAAFiPRS4AAAAAAABYj0UuAAAAAAAAWI9FLgAAAAAAAFiPRS4AAAAAAABYj0UuAAAAAAAAWI9FLgAAAAAAAFiPRS4AAAAAAABYj0UuAAAAAAAAWI9FLgAAAAAAAFiPRS4AAAAAAABYj0UuAAAAAAAAWI9FLgAAAAAAAFiPRS4AAAAAAABYj0UuAAAAAAAAWI9FLgAAAAAAAFiPRS4AAAAAAABYj0UulMuDDz4oj8fjva1YsSLYIwE4RW5urubNm6f7779fl19+uc455xxFR0crIiJCTZs2Ve/evfXMM8/o4MGDwR4VQDnt3r1bEyZM0EUXXaQmTZqoTp06SkhI0GWXXaZHH31UmzdvDvaIAEqxa9cu3X///Wrfvr3q16+vmJgYde3aVZMnT9bhw4eDPR6AX+H36OrF4ziOE+whENo2btyorl276vjx4977li9frt69ewdvKAAlfPTRR7ryyivLfFxsbKzeeOMNJSYmVsFUAHz1wgsvaPz48crPzzc+5r777tPUqVOrbigAZXrnnXd0++23Kzc3t9S8bdu2Wrp0qc4555wqngyACb9HVy/hwR4Aoa24uFh33323jh8/rqZNm2rfvn3BHgmAQUJCgvr06aMuXbooISFBzZo1U3Fxsb7//nv95z//0cKFC3XgwAFdf/31WrdunTp37hzskQGU4sknn9Qjjzwi6cRfiO+66y517dpV0dHROnjwoDZs2KDU1FTVqsUF+UAo2bBhg26++WYdOXJEDRo00Pjx49WnTx8dOXJE8+bN00svvaSvv/5a11xzjdavX6+GDRsGe2QA/w+/R1cfXMkFV1OnTtWYMWPUvn17DRo0SMnJyZK4kgsINUVFRQoLC3N9zKJFizRo0CBJ0qBBg7Rw4cKqGA1ABaSlpalfv36SpDvuuEMvv/yyateuXepjCwsLFRERUZXjAXDRq1cvrVq1SuHh4Vq5cqW6d+9eIp88ebLGjRsnSZowYYImTpwYhCkB/Bq/R1cvLHLBaPfu3TrvvPN06NAhrVixQsuXL9djjz0miUUuwFbt27fXtm3bFBsbq/379wd7HACnKC4uVvv27bV9+3Z17txZ69evV3g4F90DNli3bp26desmSbrnnns0c+bM0x5TXFysjh07asuWLWrUqJH27dtnXMQGEHr4PdoOXOcOo6SkJB06dEjDhg3T5ZdfHuxxAPjByZdGHD16NMiTAPi1Dz74QNu3b5d04gNfWOAC7LFo0SLv1yNGjCj1MbVq1dIdd9whScrOztby5curYjQAfsLv0XZgkQulmj9/vpYsWaKYmBg9++yzwR4HgB9s27ZNGzdulHTiX6IAhJYFCxZIkjwej6699lrv/T/99JO2b9+un376KVijASjDJ598IkmqX7++unTpYnzcqf9w/OmnnwZ8LgD+we/R9mCRC6fJzs7WfffdJ0maNGmSYmNjgzwRAF8dPnxY27dv15QpU3T55Zd7PyV19OjRwR0MwGnWrFkjSWrdurUaNmyouXPn6vzzz1fjxo3Vtm1bNW7cWO3atdOzzz6rgoKCIE8L4FRbtmyRJJ1zzjmuV2Ge+pfjk9sACE38Hm0nroPHacaNG6fMzEz16NFDd955Z7DHAVBBKSkpxpdKSNLf/vY3DR06tAonAlCW4uJibd26VdKJjyi/7777NG3atNMe9/XXX+uBBx5Qamqqli5dqkaNGlXxpAB+7ejRozpw4IAkqUWLFq6PPeOMM1S/fn3l5+drz549VTEegArg92j7cSUXSli1apVefvllhYeHa+bMmfJ4PMEeCYCfXHDBBVq3bp2Sk5PpNhBicnJyVFxcLEn64osvNG3aNDVr1kxvvPGGfvrpJx0+fFjp6em65JJLJEmfffaZ/vCHPwRzZAD/T15envfrBg0alPn4+vXrS5IOHToUsJkA+Be/R9uDRS54FRYW6u6775bjOBozZow6duwY7JEA+GDgwIH64osv9MUXX2jdunV68803NWjQIG3cuFG33nqrlixZEuwRAfxKfn6+9+ujR4+qXr16Wr58uW677TadccYZqlu3rnr16qWPP/5YnTt3liSlpqZq7dq1wRoZwP9z6ptQR0RElPn4yMhISdKRI0cCNhMA3/B7tP1Y5ILXU089pa1bt6ply5aaMGFCsMcB4KNGjRqpY8eO6tixo7p27apbbrlFCxcu1OzZs/Xtt9/qhhtuUEpKSrDHBHCKOnXqlPj+j3/8o9q1a3fa4+rWrat//OMf3u/feuutgM8GwN2p/S0sLCzz8SffU69u3boBmwmAb/g92n4sckGStHXrViUnJ0uSXnjhBe9l1ACqj9///ve66aabVFxcrJEjR/JJbUAIOfmx5Cf179/f+Ni+fft639j6f//7X0DnAlC2U/tbnpcgnrxyszwvbQQQGvg92h688TwkSc8//7wKCwt11lln6fDhw5o3b95pj9m8ebP3648//liZmZmSpOuuu45FMcASN9xwg+bPn6/8/HwtW7aMN84EQkRkZKSaNGmi/fv3S5ISEhKMj61Tp45iY2OVmZnpfTyA4KlTp44aN26sgwcP6vvvv3d97M8//+xd5HLrOYDQw+/RdmCRC5J+uWz622+/1a233lrm45944gnv1zt37mSRC7BEkyZNvF/v2rUriJMA+LXzzjtPK1askCQVFRW5PvZkfvKKLgDB9Zvf/EarVq3Sjh07dPz4cWM3T36KqiR16NChqsYD4Af8Hm0HXq4IADXIDz/84P2al0kAoaVXr17er7/99lvj43Jzc3XgwAFJ0plnnhnwuQCUrWfPnpJOvBQxIyPD+Lj09HTv1z169Aj4XAD8h9+j7cAiFyRJKSkpchzH9Xbqm9EvX77ce3/r1q2DNziAClmwYIH36/PPPz+IkwD4tSFDhni/Tk1NNT4uNTVVjuNIki677LKAzwWgbAMHDvR+PWvWrFIfU1xcrNmzZ0s68ebWffr0qYrRAPgJv0fbgUUuAKgGUlJSSnyEeWmef/55vfvuu5KkNm3a8JdjIMR06tRJAwYMkCS9+eabSktLO+0xmZmZevjhhyVJERERGjFiRJXOCKB0F198sfe8+sorr2j16tWnPea5557Tli1bJEn33XefateuXaUzAigdv0dXLx7n5D8FAmWYOHGiHnvsMUknruTq3bt3cAcC4NW6dWvl5eVpyJAh6tmzp84++2w1aNBAeXl5+uKLLzRnzhx9+umnkk78xXjp0qXq169fkKcG8Gtff/21unXrpuzsbNWpU0ejR4/W1Vdfrbp162rdunVKTk72vrH1pEmTNG7cuCBPDOCkDRs2qEePHjpy5IgaNGigv//97+rTp4+OHDmiefPm6d///rckqW3btlq/fv1pn6oKIDj4Pbp6YZEL5cYiFxC6WrduXa43wGzRooVeffVVXXnllVUwFQBffPLJJ7rxxhuVlZVVau7xePTQQw+V+BAYAKHhnXfe0e23367c3NxS87Zt22rp0qU655xzqngyACb8Hl298JE8AFANvP/++1q6dKk+/fRT7dixQ1lZWTp48KDq1q2rpk2b6oILLtC1116r3/3ud6pXr16wxwXgomfPnvryyy/1wgsvaNGiRdq5c6cKCwvVrFkz9e7dW6NGjdJvf/vbYI8JoBTXXXedNm3apH/+859aunSpvv/+e0VEROicc87RTTfdpJEjR3IeBkIMv0dXL1zJBQAAAAAAAOvxxvMAAAAAAACwHotcAAAAAAAAsB6LXAAAAAAAALAei1wAAAAAAACwHotcAAAAAAAAsB6LXAAAAAAAALBeeKB2PH36dE2ePFmZmZnq3LmzXnjhBV188cVlbldcXKwff/xRDRs2lMfjCdR4gLUcx1FeXp6aN2+uWrUCs07ta38lOgy4qYr+SpyDgUDhHAzYi3MwYLdyd9gJgHnz5jkRERHOq6++6nz55ZfOXXfd5TRq1MjJysoqc9s9e/Y4krhx41bGbc+ePYGob6X6S4e5cSvfLVD9rWyH6S83buW7cQ7mxs3eG+dgbtzsvpXVYY/jOI78rFu3buratav+9a9/STqxKp2QkKBRo0bpb3/7m+u2OTk5atSokfbs2aOoqCh/jwZYLzc3VwkJCcrOzlZ0dLTf91+Z/kp0GHAT6P5KnIOBQOIcDNiLczBgt/J22O8vVywsLFRGRobGjx/vva9WrVrq16+fVq9efdrjCwoKVFBQ4P0+Ly9PkhQVFUW5AReBuIy5ov2V6DDgi0C9DIFzMFA1OAcD9uIcDNitrA77/cXIBw4cUFFRkeLi4krcHxcXp8zMzNMen5ycrOjoaO8tISHB3yMBKKeK9leiw0Ao4RwM2ItzMGA3zsFAaAj6pyuOHz9eOTk53tuePXuCPRKACqDDgL3oL2A3OgzYi/4CgeH3lyvGxsYqLCxMWVlZJe7PyspSfHz8aY+PjIxUZGSkv8cA4IOK9leiw0Ao4RwM2ItzMGA3zsFAaPD7lVwRERHq0qWL0tLSvPcVFxcrLS1N3bt39/fTAfAj+gvYjQ4D9qK/gN3oMBAa/H4llySNHTtWw4YN00UXXaSLL75YU6dOVX5+vkaMGBGIpwPgR/QXsBsdBuxFfwG70WEg+AKyyHXzzTdr//79evTRR5WZmakLLrhAy5YtO+1N+ACEHvoL2I0OA/aiv4Dd6DAQfB7HcZxgD3Gq3NxcRUdHKycnh49OBUoR6h0J9fmAYAr1foT6fECwhXpHQn0+IJhCvR+hPh8QbOXtSNA/XREAAAAAAACoLBa5AAAAAAAAYD0WuQAAAAAAAGA9FrkAAAAAAABgPRa5AAAAAAAAYD0WuQAAAAAAAGA9FrkAAAAAAABgPRa5AAAAAAAAYD0WuQAAAAAAAGA9FrkAAAAAAABgPRa5AAAAAAAAYL3wYA8AAAAA/xs7dqwxmzp1qjHr1q2bMVuwYIHrc7Zo0aLMuQAAAAKFK7kAAAAAAABgPRa5AAAAAAAAYD0WuQAAAAAAAGA9FrkAAAAAAABgPRa5AAAAAAAAYD0WuQAAAAAAAGC98GAPAAAAAN9MmTLFmE2dOtWYhYWFGbO1a9f6lElSixYtXHMAAIBA4kouAAAAAAAAWI9FLgAAAAAAAFiPRS4AAAAAAABYj0UuAAAAAAAAWI9FLgAAAAAAAFiPRS4AAAAAAABYL9zfO5w4caIee+yxEve1a9dOW7du9fdToYr8+uf5axMnTjRmM2fONGb33HOPryMhQOhv1SguLjZm3333nU/7TElJMWa5ubmu2+7evduYpaamGrMePXoYs4cfftiY9e7d23WeOnXquOYwo8PVz9ixY13zqVOnGjPHcYxZUVGRMbvxxhuN2ZAhQ1znge/ob/C98sorxuyuu+4yZsuXLzdml19+eaVmgj3ocPm4/R4sSTt27DBm//nPf4xZZmamzzOZrFmzxjX/3//+59N+GzRoYMxGjBhhzO69917X/Xbo0MGneaobvy9ySdJ5552njz766JcnCQ/I0wAIAPoL2I0OA/aiv4Dd6DAQfAFpXXh4uOLj4wOxawABRn8Bu9FhwF70F7AbHQaCLyDvybV9+3Y1b95cZ511lm677TbXl8IUFBQoNze3xA1A8FSkvxIdBkIN52DAXpyDAbtxDgaCz++LXN26dVNKSoqWLVumGTNmaOfOnbrsssuUl5dX6uOTk5MVHR3tvSUkJPh7JADlVNH+SnQYCCWcgwF7cQ4G7MY5GAgNfl/kGjBggG666SZ16tRJiYmJevfdd5Wdna358+eX+vjx48crJyfHe9uzZ4+/RwJQThXtr0SHgVDCORiwF+dgwG6cg4HQEPB3wmvUqJHatm1r/JSEyMhIRUZGBnoMAD4oq78SHQZCGedgwF6cgwG7cQ4GgiPgi1yHDh3SN998o9///veBfioEyMyZM11zj8djzBYuXGjM7rnnHp9nQtWo6f394osvjNnDDz/s836LioqM2bvvvuvzfk0cx3HN3Trsln322WfG7OqrrzZmDz30kOs8TzzxhGuO8qvpHbbFlClTjNnUqVNdtw0LCzNmbv+vcdtu7Nixrs+JqkF/A2PGjBnG7MEHHzRmbufDgQMHGrOmTZuWa66Kcju3u83apEkT1/3OmTPHmLVq1arsweBFh0v31FNPueaPPvpoFU1SeW5dc5Ofn2/M/vWvfxmzxYsXu+43LS3NmJ1zzjllD1ZN+P3lin/961+Vnp6u7777Tp999pkGDRqksLAw3Xrrrf5+KgB+Rn8Bu9FhwF70F7AbHQZCg9+v5Pr+++9166236uDBg2rSpIl69uypNWvWlPmvBgCCj/4CdqPDgL3oL2A3OgyEBr8vcs2bN8/fuwRQRegvYDc6DNiL/gJ2o8NAaPD7yxUBAAAAAACAqsYiFwAAAAAAAKzHIhcAAAAAAACs5/f35IKdXn75ZWOWnZ3tum1kZKQxGzdunK8j+aygoMCYjR8/3pj17NnTmA0ePLhSM8FOb775pjF75513AvKcZ5xxhjEbMmRIQJ6zRYsWxsztz/6UKVOMWUpKijFz+2hkSbryyiuNWa9evVy3BULVggULjNlf//pXY+Y4jut+i4qKfNq2W7duxuySSy5xfU7AZlOnTjVm+fn5Pu3T4/EYs0ceecR1W1/flHzYsGHGbP/+/cZsx44drvu99tprjdltt91mzO6//35jVrt2bdfnRPWzbNkyY/b4449X4SSVExEREZD9up2fjx07Zsz27Nnjul+3v5+MGTOm7MGqCa7kAgAAAAAAgPVY5AIAAAAAAID1WOQCAAAAAACA9VjkAgAAAAAAgPVY5AIAAAAAAID1WOQCAAAAAACA9cKDPQCqzurVq43Z6NGjjVlhYaHrfseNG2fM+vbtW+Zc/vbpp58as3/+85/GbMuWLcZs8ODBlZoJdurZs6cxi4uLc902ISHBmD311FPGrEePHsasbt26rs8ZCAcPHjRmZX2MscnRo0dd87Zt2/q0X8BWYWFhxqyoqMjnbbt162bM5s2bV/ZggKUcx6nS51u0aJEx69WrV0Ce8/333zdmL730kjGbMWOG636/+uorY/b3v//dmN10003G7Oyzz3Z9TlQ/4eHmZQaPx1OFk1TOqlWrXPOuXbv6tN/vv//emLVs2dKnfeIXXMkFAAAAAAAA67HIBQAAAAAAAOuxyAUAAAAAAADrscgFAAAAAAAA67HIBQAAAAAAAOuxyAUAAAAAAADrscgFAAAAAAAA64UHewD417vvvmvMHn74YWN25MgRY9a1a1fX53TbbyD873//c81vuOEGn/Zb1n8nap6rr77amO3du9d1223bthmzdu3a+TyTL7777jvX3K1Td999tzHLyckxZg0bNjRmKSkprvPEx8e75kB1U1RUZMwcx/F52+bNmxuzFi1alD0YEKLS09Nd8yuuuMKn/TZq1MiYpaamGrNevXr59HyV0blzZ2P25z//2Zi5/V1Bknbt2uXTPIMGDTJm77zzjjFr1aqVT8+H0NavXz9jNmnSJNdtx44da8zczl1uf5f7+eefjdmKFSuM2XXXXWfMJCkzM9M1R3BwJRcAAAAAAACsxyIXAAAAAAAArMciFwAAAAAAAKzHIhcAAAAAAACsxyIXAAAAAAAArMciFwAAAAAAAKwXXtENVq5cqcmTJysjI0N79+5VamqqBg4c6M0dx9GECRP00ksvKTs7Wz169NCMGTN07rnn+nPuGu2BBx4wZu+9954x++qrr4xZnTp1jJnbx/5KUv369V1zX6xcudKYXXPNNa7bHj582Jh17NjRmP3hD38oezDL0d+q065dO7/v8/vvvzdmd955pzHbtGmT636zsrJ8mmf48OHGzO3jn916CHd0uHoKCwszZkVFRT5vW6sW/5YZSuiv/6Smpvq8bdOmTY3Z9ddfb8x69erl83NWtd/85jfGbM6cOa7b9uzZ06fn/PLLL43Z1q1bjVmrVq18er5goMP+8Ze//MU1v+mmm4xZ3bp1jVlMTIwxKywsNGaffPKJMRsxYoQxq4zjx48HZL84ocK//eTn56tz586aPn16qfkzzzyjadOmaebMmVq7dq3q16+vxMREHT16tNLDAqgc+gvYjQ4D9qK/gN3oMGCHCl/JNWDAAA0YMKDUzHEcTZ06VQ8//LBuuOEGSdLs2bMVFxenRYsW6ZZbbqnctAAqhf4CdqPDgL3oL2A3OgzYwa/Xse/cuVOZmZnq16+f977o6Gh169ZNq1evLnWbgoIC5ebmlrgBqHq+9Feiw0Co4BwM2ItzMGA3zsFA6PDrIldmZqYkKS4ursT9cXFx3uzXkpOTFR0d7b0lJCT4cyQA5eRLfyU6DIQKzsGAvTgHA3bjHAyEjqC/I+n48eOVk5Pjve3ZsyfYIwGoADoM2Iv+Anajw4C96C8QGH5d5IqPj5d0+id1ZWVlebNfi4yMVFRUVIkbgKrnS38lOgyECs7BgL04BwN24xwMhI4Kv/G8mzZt2ig+Pl5paWm64IILJEm5ublau3at7r33Xn8+lfV+/vln1/zvf/+7Mfu///s/Y+bxeIyZ2/84X3vtNWPWpEkTY1YZH3/8sTFz++jYw4cPu+533Lhxxiw5ObnswWoo+hsaNm3aZMwuv/xyY5aTk2PM3P6CJEkPPfSQMXP7GHK3N1F1+38RAoMO26uoqMiYOY7j87bz5s3zeSZULfp7usLCQmOWnZ3t834vuugiY+b2O3Z1ERsbG+wRqiU6XH61arlfZ3PmmWf6/TkjIiKM2RVXXGHMRowY4fNzHjx40JgNGTLE5/26CdTf221T4UWuQ4cOaceOHd7vd+7cqY0bNyomJkYtW7bU6NGj9eSTT+rcc89VmzZt9Mgjj6h58+YaOHCgP+cG4AP6C9iNDgP2or+A3egwYIcKL3KtX79effr08X4/duxYSdKwYcOUkpKicePGKT8/X3fffbeys7PVs2dPLVu2THXq1PHf1AB8Qn8Bu9FhwF70F7AbHQbsUOFFrt69e7teOu/xePT444/r8ccfr9RgAPyP/gJ2o8OAvegvYDc6DNgh6J+uCAAAAAAAAFQWi1wAAAAAAACwHotcAAAAAAAAsF6F35ML/jF9+nTX/N///rffn9Pto1PT09ONWd26dX1+zn379hmzk2/WWBq3j4a+6aabXJ8zOTm5zLmAYFqyZIkxe+CBB4yZ2/tAPPfcc8ZszJgx5RsMQFCEhYUZs6KiIp+3BWy2a9cuY/b666/7vN/Bgwf7vC2AmmXixImu+WeffWbM3P4/tWHDBp/mcft7giQNHTrUp/1WN1zJBQAAAAAAAOuxyAUAAAAAAADrscgFAAAAAAAA67HIBQAAAAAAAOuxyAUAAAAAAADrscgFAAAAAAAA64UHe4Ca6u23367y5zx48KAx++c//+lTJkmO4xgzj8dT9mAV1KpVK7/vE6hKeXl5xmzbtm3GrEmTJsbs1ltvrdRMAALrd7/7nTFzO1e6nWMlqaioyOeZgFB23333GbOyeuGmV69ePm9bE7gdW7fs6quvNmaJiYmVmgkoj5ycHGO2d+9eY7ZgwQJj9tJLL7k+5/79+41ZQUGB67a+uPnmm13zWrW4hkniSi4AAAAAAABUAyxyAQAAAAAAwHoscgEAAAAAAMB6LHIBAAAAAADAeixyAQAAAAAAwHoscgEAAAAAAMB64cEeoKa66KKLXPNNmzZV0ST2mTFjhmveqlUrY/bnP//Z3+MAFTZ48GBj1rFjR2O2efNmY3bPPfcYs8WLF5dvMACVMmXKFGPm8XiMWVhYmDErKipyfU63bd0+anzMmDHG7JJLLnF9TsBf0tPTjdknn3xizNz6hMrx9djyM0FVcPud9pZbbjFmBQUFgRinyg0dOtQ1f/75543ZgAED/D1OyOJKLgAAAAAAAFiPRS4AAAAAAABYj0UuAAAAAAAAWI9FLgAAAAAAAFiPRS4AAAAAAABYj0UuAAAAAAAAWI9FLgAAAAAAAFgvvKIbrFy5UpMnT1ZGRob27t2r1NRUDRw40JsPHz5cr732WoltEhMTtWzZskoPW5289NJLlcr97ciRI8asdevWrtvu27fPmNWuXduY3XPPPcasZcuWxmz9+vWu88CM/oaGyMhIY7ZgwQJj1rt3b2P23//+15hdf/31rvO8+eabxqx+/fqu26Jq0eGqsXr1amPm1tGpU6caM8dxjFlRUZFP25W17fz5842Z23+H23P+9a9/dZ1n8uTJrnlNRn9Pd/jwYWOWn5/v834bNWpkzNx+NwXc0OHge/bZZ41ZQUFBFU4SHF9//bVrvnXrVmM2YMAAf48Tsip8JVd+fr46d+6s6dOnGx9z1VVXae/evd6b21+gAFQd+gvYjQ4D9qK/gN3oMGCHCl/JNWDAgDJXASMjIxUfH+/zUAACg/4CdqPDgL3oL2A3OgzYISDvybVixQo1bdpU7dq107333quDBw8aH1tQUKDc3NwSNwDBU5H+SnQYCDWcgwF7cQ4G7MY5GAg+vy9yXXXVVZo9e7bS0tI0adIkpaena8CAAcb3jEhOTlZ0dLT3lpCQ4O+RAJRTRfsr0WEglHAOBuzFORiwG+dgIDRU+OWKZbnlllu8X59//vnq1KmTzj77bK1YsUJ9+/Y97fHjx4/X2LFjvd/n5uZScCBIKtpfiQ4DoYRzMGAvzsGA3TgHA6EhIC9XPNVZZ52l2NhY7dixo9Q8MjJSUVFRJW4AQkNZ/ZXoMBDKOAcD9uIcDNiNczAQHH6/kuvXvv/+ex08eFDNmjUL9FOhDF988YUxS0pKMmYHDhxw3W9ERIQxGzRokDGbNm2a634RfPS36rVr186YbdiwwZj99re/NWbvvPOO63MOHz7cmM2aNcuYNWjQwHW/CD46XLrVq1e75rfeeqsx2717tzELCwszZm4vOfN1u2A859SpU13nmTx5smuO8qO/vrvjjjuMWcuWLatwkppj8ODBwR4h5NBh/7vzzjuN2fbt243ZsWPHjNnPP/9szJo0aeI6j9sHETz88MPG7MUXXzRmZZ1nUbYKL3IdOnSoxGr0zp07tXHjRsXExCgmJkaPPfaYhgwZovj4eH3zzTcaN26czjnnHCUmJvp1cAAVR38Bu9FhwF70F7AbHQbsUOFFrvXr16tPnz7e70++jnjYsGGaMWOGNm3apNdee03Z2dlq3ry5+vfvryeeeEKRkZH+mxqAT+gvYDc6DNiL/gJ2o8OAHSq8yNW7d285jmPM33///UoNBCBw6C9gNzoM2Iv+Anajw4AdAv7G8wAAAAAAAECgscgFAAAAAAAA67HIBQAAAAAAAOtV+D25YK9//etfxuzTTz/1eb/33HOPMZs2bZrP+wVQUnx8vDFLT083ZkOGDHHd79tvv23MioqKjNn8+fONWXg4pxcE1+rVq43ZpZde6rqtx+MxZm7vx+LWl0BsF4zndNsOqKiVK1cas7L+7LupzLbVwXvvvWfMrrnmGp/326lTJ2N23XXX+bxfoLyGDx9uzHr06GHMYmJijFlaWpoxGzhwoOs8ERERxiwrK8un50TlcSUXAAAAAAAArMciFwAAAAAAAKzHIhcAAAAAAACsxyIXAAAAAAAArMciFwAAAAAAAKzHIhcAAAAAAACsx2e8VzMPP/ywMXvrrbd82uekSZNc82HDhvm0XwD+07ZtW2M2ZcoU123vu+8+Y7Zo0SJj9u677xqz66+/3vU5gUD75z//acw8Ho/rtmFhYcasqKgoZLYLxnO6bQdU1MKFC41ZWT1106FDB5+3tcV3331nzNavX2/Myjqu5513njH76KOPjFlsbKzrfoFAO/fcc33a7ne/+52fJzlh6dKlxuyLL74IyHPWhP/3lQdXcgEAAAAAAMB6LHIBAAAAAADAeixyAQAAAAAAwHoscgEAAAAAAMB6LHIBAAAAAADAeixyAQAAAAAAwHrhwR4AFXfdddcZs+XLlxuzI0eOGDO3jwv+05/+5DpPgwYNXHOgOlq1apVrnpaWZsweeughY1a7dm2fZzK58sorXfNRo0YZs6SkJGM2YsQIY7Zt2zZjxseMoypcfPHFxuytt95y3bZbt27GbPDgwcZs7dq1xmz+/PnGrKioyJg5jmPMKrOt23YtWrQwZm7/HUBF3XPPPcbsgQceCMh+q4tZs2YZsyeffNLn/d59993GjPM3ahq3c6Xk3sPHHnvM3+PolVdecc0TExP9/pw24kouAAAAAAAAWI9FLgAAAAAAAFiPRS4AAAAAAABYj0UuAAAAAAAAWI9FLgAAAAAAAFiPRS4AAAAAAABYr0KLXMnJyeratasaNmyopk2bauDAgad9TPzRo0eVlJSkxo0bq0GDBhoyZIiysrL8OjQA39BhwF70F7AbHQbsRX8Be3gcx3HK++CrrrpKt9xyi7p27arjx4/r73//uzZv3qyvvvpK9evXlyTde++9Wrp0qVJSUhQdHa2RI0eqVq1a+vTTT8v1HLm5uYqOjlZOTo6ioqJ8+6+ywJEjR1zztLQ0Y3bdddcZM4/HY8wGDhxozBYuXOg6D0JHZTpChyvmp59+Mmbt2rVz3fbgwYPGLDMz05g1bdq07MH8bPPmzcbssssuM2Y5OTnGbO7cucbslltuKd9g1RD9DQ3/+c9/XPNLLrnEmLVo0cKYrVmzxphdeumlxiwsLMyYFRUVGbPKbOu23ZAhQ4zZvHnzXOep7uiwf7333nvG7Nprr/V5v/Pnzzdmbn++bVKrlvlaBbe/D5T1e8b7779vzDp16lT2YCGM/lZccXGxMVuxYoUx27RpkzG79957XZ8zMjKyzLn8ye338j//+c+u2y5atMjP00jnn3++MVu8eLHrtq1bt/bzNKGlvB0Jr8hOly1bVuL7lJQUNW3aVBkZGerVq5dycnL0yiuvaO7cubriiiskSbNmzVKHDh20Zs0a118aAQQeHQbsRX8Bu9FhwF70F7BHpd6T6+S/4sfExEiSMjIydOzYMfXr18/7mPbt26tly5ZavXp1ZZ4KQADQYcBe9BewGx0G7EV/gdBVoSu5TlVcXKzRo0erR48e6tixo6QTl/pFRESoUaNGJR4bFxdnvAywoKBABQUF3u9zc3N9HQlABdBhwF70F7AbHQbsRX+B0ObzlVxJSUnavHlzpd+bITk5WdHR0d5bQkJCpfYHoHzoMGAv+gvYjQ4D9qK/QGjzaZFr5MiRWrJkiZYvX17iDVjj4+NVWFio7OzsEo/PyspSfHx8qfsaP368cnJyvLc9e/b4MhKACqDDgL3oL2A3OgzYi/4Coa9Ci1yO42jkyJFKTU3Vxx9/rDZt2pTIu3Tpotq1a5f4ZMBt27Zp9+7d6t69e6n7jIyMVFRUVIkbgMCgw4C96C9gNzoM2Iv+Avao0HtyJSUlae7cuVq8eLEaNmzofX1xdHS06tatq+joaN15550aO3asYmJiFBUVpVGjRql79+58osSvzJgxwzV/4IEHjJnbxwLXq1fPmI0bN67swVCt0eGKOXbsmDE7ePCgz/v97LPPjNnAgQN93q+vOnToYMzOPPNMY3byTVdRNeiv/9x4440B2a/bce7WrZsxW7t2rTFzHMf1OYuKiozZqVcZ/Nqll15qzCr7EhyUjg6frlWrVsasZcuWxmzXrl2u+73pppuM2fbt241Z48aNjdnrr79uzNx62rp1a2MmSddff70xS09P9+k53Y7ru+++6zqP2+8ENVlN7e/GjRuN2alvsu+vfUonPrnS305dfPw1t78jb9iwwe+zSCfeq81k1apVxoyF0PKp0CLXyYWZ3r17l7h/1qxZGj58uCTp+eefV61atTRkyBAVFBQoMTFRL774ol+GBVA5dBiwF/0F7EaHAXvRX8AeFVrkKutfEyWpTp06mj59uqZPn+7zUAACgw4D9qK/gN3oMGAv+gvYw+dPVwQAAAAAAABCBYtcAAAAAAAAsB6LXAAAAAAAALAei1wAAAAAAACwXoXeeB4V8/bbbxuzxx9/3Of9RkZGGrNp06YZM5s/vhYIBreP6b366qtdt3X7iO6bb77ZmI0dO9aYDR061PU5fbV27Vpj9tVXXxmz8HDzKSQ6OrpSMwHVzYIFC4zZLbfcYsw+++wz1/2GhYUZs/nz5xszfidAKPjNb35jzNz+7P/973933e/s2bON2X333WfMiouLjdn7779vzNzelLxBgwbGTJKaNWtmzPbv32/MrrnmGmOWnJxszDp06OA6D3CqjIwMv+/TrZ+S9Oabb/r9OY8fP27MyvOhAr7o1q2bMZs6daoxc/v7B8qHK7kAAAAAAABgPRa5AAAAAAAAYD0WuQAAAAAAAGA9FrkAAAAAAABgPRa5AAAAAAAAYD0WuQAAAAAAAGA9jxOoz8z0UW5urqKjo5WTk2P9x2deddVVxuzDDz/0eb+zZs0yZnfccYfP+4UdQr0joT6fv+Tk5LjmDz74oDF77bXXjFlBQYHPM5mU9b95j8fj034vueQSY+b20e81Waj3I9TnA4It1DsS6vP5y5YtW1zz3bt3G7Mnn3zSmP3www/GbNeuXcbM7Txb1jm2c+fOxiw5OdmYJSYmuu4Xpwv1foTifMePHzdmZ599tjHbs2dPIMYJOW5/33frr1vvYVbejnAlFwAAAAAAAKzHIhcAAAAAAACsxyIXAAAAAAAArMciFwAAAAAAAKzHIhcAAAAAAACsxyIXAAAAAAAArBce7AGqs65duxqzDz/80HXbV1991ZjdcccdPs8EwD+io6Nd85kzZxqzK6+80ph98sknxmzhwoXGLFAf1dyxY0dj9t///jcgzwkAgJsOHTr4nCcmJhqz7OxsY/bGG28Ys7/85S/G7JFHHjFmkjRixAhj1qpVK9dtgUALDzcvF6xbt86YbdiwwZi99957lZrJ5KWXXjJmR48eNWbt2rUzZmX197rrrjNmDRs2dN0WgcOVXAAAAAAAALAei1wAAAAAAACwHotcAAAAAAAAsB6LXAAAAAAAALAei1wAAAAAAACwHotcAAAAAAAAsJ9TAU899ZRz0UUXOQ0aNHCaNGni3HDDDc7WrVtLPObyyy93JJW43XPPPeV+jpycHEeSk5OTU5HRgBqjMh2hw0Bw0V/AbnQYsBf9BexW3o5U6Equ9PR0JSUlac2aNfrwww917Ngx9e/fX/n5+SUed9ddd2nv3r3e2zPPPFPBpTcAgUCHAXvRX8BudBiwF/0F7BFekQcvW7asxPcpKSlq2rSpMjIy1KtXL+/99erVU3x8vH8mBOA3dBiwF/0F7EaHAXvRX8AelXpPrpycHElSTExMifvnzJmj2NhYdezYUePHj9fhw4eN+ygoKFBubm6JG4CqQYcBe9FfwG50GLAX/QVCV4Wu5DpVcXGxRo8erR49eqhjx47e+4cOHapWrVqpefPm2rRpkx588EFt27ZNCxcuLHU/ycnJeuyxx3wdA4CP6DBgL/oL2I0OA/aiv0Bo8ziO4/iy4b333qv33ntPn3zyiVq0aGF83Mcff6y+fftqx44dOvvss0/LCwoKVFBQ4P0+NzdXCQkJysnJUVRUlC+jAdVabm6uoqOjK90ROgxUPfoL2I0OA/aiv4Ddytthn67kGjlypJYsWaKVK1e6FluSunXrJknGckdGRioyMtKXMQD4iA4D9qK/gN3oMGAv+guEvgotcjmOo1GjRik1NVUrVqxQmzZtytxm48aNkqRmzZr5NCAA/6HDgL3oL2A3OgzYi/4C9qjQIldSUpLmzp2rxYsXq2HDhsrMzJQkRUdHq27duvrmm280d+5cXX311WrcuLE2bdqkMWPGqFevXurUqVNA/gMAlB8dBuxFfwG70WHAXvQXsEeF3pPL4/GUev+sWbM0fPhw7dmzR7fffrs2b96s/Px8JSQkaNCgQXr44YfL/bpif71WGqiuKtMROgwEF/0F7EaHAXvRX8BuAXlPrrLWwxISEpSenl6RXQKoQnQYsBf9BexGhwF70V/AHrWCPQAAAAAAAABQWSxyAQAAAAAAwHoscgEAAAAAAMB6LHIBAAAAAADAeixyAQAAAAAAwHoscgEAAAAAAMB6LHIBAAAAAADAeixyAQAAAAAAwHoscgEAAAAAAMB6LHIBAAAAAADAeuHBHuDXHMeRJOXm5gZ5EiA0nezGya6EGjoMmNFfwG50GLAX/QXsVt4Oh9wiV15eniQpISEhyJMAoS0vL0/R0dHBHuM0dBgoG/0F7EaHAXvRX8BuZXXY44TYUnZxcbF+/PFHNWzYUB6PR7m5uUpISNCePXsUFRUV7PFCDsfHrLoeG8dxlJeXp+bNm6tWrdB7xfGpHc7Ly6uWPwN/qa5/Rv2lOh4fm/rLObhsHB+z6npsbOow52B31fXPqL9Ux+NjU385B5eN42NWXY9NeTsccldy1apVSy1atDjt/qioqGr1A/I3jo9ZdTw2ofivTyed2mGPxyOpev4M/Inj4666HR9b+nuq6vYz8DeOj1l1PDa2dJhzcPlwfNxVt+NjS39PVd1+Bv7G8TGrjsemPB0OvSVsAAAAAAAAoIJY5AIAAAAAAID1Qn6RKzIyUhMmTFBkZGSwRwlJHB8zjk3w8TNwx/Fxx/EJPn4G7jg+Zhyb4ONn4I7j447jE3z8DNxxfMxq+rEJuTeeBwAAAAAAACoq5K/kAgAAAAAAAMrCIhcAAAAAAACsxyIXAAAAAAAArMciFwAAAAAAAKwX0otc06dPV+vWrVWnTh1169ZN69atC/ZIQbFy5Updd911at68uTwejxYtWlQidxxHjz76qJo1a6a6deuqX79+2r59e3CGrWLJycnq2rWrGjZsqKZNm2rgwIHatm1bicccPXpUSUlJaty4sRo0aKAhQ4YoKysrSBPXLHT4BDpsRodDF/09gf6a0d/QRodPoMNmdDh00d8T6K8Z/TUL2UWut956S2PHjtWECRP0+eefq3PnzkpMTNS+ffuCPVqVy8/PV+fOnTV9+vRS82eeeUbTpk3TzJkztXbtWtWvX1+JiYk6evRoFU9a9dLT05WUlKQ1a9boww8/1LFjx9S/f3/l5+d7HzNmzBi98847WrBggdLT0/Xjjz9q8ODBQZy6ZqDDv6DDZnQ4NNHfX9BfM/obuujwL+iwGR0OTfT3F/TXjP66cELUxRdf7CQlJXm/Lyoqcpo3b+4kJycHcargk+SkpqZ6vy8uLnbi4+OdyZMne+/Lzs52IiMjnTfffDMIEwbXvn37HElOenq64zgnjkXt2rWdBQsWeB+zZcsWR5KzevXqYI1ZI9Dh0tFhd3Q4NNDf0tFfd/Q3dNDh0tFhd3Q4NNDf0tFfd/T3FyF5JVdhYaEyMjLUr18/7321atVSv379tHr16iBOFnp27typzMzMEscqOjpa3bp1q5HHKicnR5IUExMjScrIyNCxY8dKHJ/27durZcuWNfL4VBU6XH50uCQ6HHz0t/zob0n0NzTQ4fKjwyXR4eCjv+VHf0uiv78IyUWuAwcOqKioSHFxcSXuj4uLU2ZmZpCmCk0njwfHSiouLtbo0aPVo0cPdezYUdKJ4xMREaFGjRqVeGxNPD5ViQ6XHx3+BR0ODfS3/OjvL+hv6KDD5UeHf0GHQwP9LT/6+wv6W1J4sAcA/CUpKUmbN2/WJ598EuxRAPiADgP2or+A3egwYC/6W1JIXskVGxursLCw0975PysrS/Hx8UGaKjSdPB41/ViNHDlSS5Ys0fLly9WiRQvv/fHx8SosLFR2dnaJx9e041PV6HD50eET6HDooL/lR39PoL+hhQ6XHx0+gQ6HDvpbfvT3BPp7upBc5IqIiFCXLl2Ulpbmva+4uFhpaWnq3r17ECcLPW3atFF8fHyJY5Wbm6u1a9fWiGPlOI5Gjhyp1NRUffzxx2rTpk2JvEuXLqpdu3aJ47Nt2zbt3r27RhyfYKHD5UeH6XCoob/lR3/pbyiiw+VHh+lwqKG/5Ud/6a9RUN/23sW8efOcyMhIJyUlxfnqq6+cu+++22nUqJGTmZkZ7NGqXF5enrNhwwZnw4YNjiRnypQpzoYNG5xdu3Y5juM4Tz/9tNOoUSNn8eLFzqZNm5wbbrjBadOmjXPkyJEgTx549957rxMdHe2sWLHC2bt3r/d2+PBh72P+9Kc/OS1btnQ+/vhjZ/369U737t2d7t27B3HqmoEO/4IOm9Hh0ER/f0F/zehv6KLDv6DDZnQ4NNHfX9BfM/prFrKLXI7jOC+88ILTsmVLJyIiwrn44oudNWvWBHukoFi+fLkj6bTbsGHDHMc58fGpjzzyiBMXF+dERkY6ffv2dbZt2xbcoatIacdFkjNr1izvY44cOeL8+c9/ds444wynXr16zqBBg5y9e/cGb+gahA6fQIfN6HDoor8n0F8z+hva6PAJdNiMDocu+nsC/TWjv2Yex3Ec/1wTBgAAAAAAAARHSL4nFwAAAAAAAFARLHIBAAAAAADAeixyAQAAAAAAwHoscgEAAAAAAMB6LHIBAAAAAADAeixyAQAAAAAAwHoscgEAAAAAAMB6LHIBAAAAAADAeixyAQAAAAAAwHoscgEAAAAAAMB6LHIBAAAAAADAeixyAQAAAAAAwHr/PwDgWJ4jURzvAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1500x1700 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_num_images(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "from paddle.vision.transforms import Normalize\n",
    "\n",
    "def get_MNIST_dataloader():\n",
    "    # 定义图像归一化处理方法，这里的CHW指图像格式需为 [C通道数，H图像高度，W图像宽度]\n",
    "    transform = Normalize(mean=[127.5], std=[127.5], data_format='chw')\n",
    "    # 下载数据集并初始化 dataset\n",
    "    train_dataset = paddle.vision.datasets.MNIST(mode='train', transform=transform)\n",
    "    test_dataset = paddle.vision.datasets.MNIST(mode='test', transform=transform)\n",
    "\n",
    "    # 定义并初始化数据读取器\n",
    "    train_loader = paddle.io.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=1, drop_last=True)\n",
    "    test_loader = paddle.io.DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=1, drop_last=False)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = get_MNIST_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[128, 1, 28, 28]\n",
      "[128, 1]\n"
     ]
    }
   ],
   "source": [
    "for batch_id, data in enumerate(train_loader()):\n",
    "    images, labels = data\n",
    "    print(images.shape)\n",
    "    print(labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6736"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import visualdl\n",
    "import visualdl.server.app \n",
    "visualdl.server.app.run('./run',\n",
    "                        host=\"127.0.0.1\",\n",
    "                        port=8080,\n",
    "                        cache_timeout=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建第一个模型\n",
    "class AutoEncoder(nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 32))\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(32, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 28 * 28),\n",
    "            nn.Sigmoid())\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        encoded = self.encoder(inputs)\n",
    "        decoded = self.decoder(encoded)\n",
    "\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      " Layer (type)       Input Shape          Output Shape         Param #    \n",
      "===========================================================================\n",
      "   Linear-73          [[784]]               [128]             100,480    \n",
      "    Tanh-55           [[128]]               [128]                0       \n",
      "   Linear-74          [[128]]                [64]              8,256     \n",
      "    Tanh-56            [[64]]                [64]                0       \n",
      "   Linear-75           [[64]]                [12]               780      \n",
      "    Tanh-57            [[12]]                [12]                0       \n",
      "   Linear-76           [[12]]                [3]                39       \n",
      "   Linear-77           [[3]]                 [12]               48       \n",
      "    Tanh-58            [[12]]                [12]                0       \n",
      "   Linear-78           [[12]]                [64]               832      \n",
      "    Tanh-59            [[64]]                [64]                0       \n",
      "   Linear-79           [[64]]               [128]              8,320     \n",
      "    Tanh-60           [[128]]               [128]                0       \n",
      "   Linear-80          [[128]]               [784]             101,136    \n",
      "  Sigmoid-10          [[784]]               [784]                0       \n",
      "===========================================================================\n",
      "Total params: 219,891\n",
      "Trainable params: 219,891\n",
      "Non-trainable params: 0\n",
      "---------------------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.02\n",
      "Params size (MB): 0.84\n",
      "Estimated Total Size (MB): 0.86\n",
      "---------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total_params': 219891, 'trainable_params': 219891}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoEncoder()\n",
    "paddle.jit.save(model, './run/mnist_experiment/auto1', [paddle.static.InputSpec([-1,1,28,28])])\n",
    "model = paddle.Model(network)\n",
    "model.summary((784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建第一个模型\n",
    "class AutoEncoder1(nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder1, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 328),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(328, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, 12))\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(12, 32),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 328),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(328, 28 * 28),\n",
    "            nn.Sigmoid())\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        encoded = self.encoder(inputs)\n",
    "        decoded = self.decoder(encoded)\n",
    "\n",
    "        return encoded, decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      " Layer (type)       Input Shape          Output Shape         Param #    \n",
      "===========================================================================\n",
      "  Linear-141          [[784]]               [328]             257,480    \n",
      "   Tanh-101           [[328]]               [328]                0       \n",
      "  Linear-142          [[328]]                [64]             21,056     \n",
      "   Tanh-102            [[64]]                [64]                0       \n",
      "  Linear-143           [[64]]                [32]              2,080     \n",
      "   Tanh-103            [[32]]                [32]                0       \n",
      "  Linear-144           [[32]]                [12]               396      \n",
      "  Linear-145           [[12]]                [32]               416      \n",
      "   Tanh-104            [[32]]                [32]                0       \n",
      "  Linear-146           [[32]]                [64]              2,112     \n",
      "   Tanh-105            [[64]]                [64]                0       \n",
      "  Linear-147           [[64]]               [328]             21,320     \n",
      "   Tanh-106           [[328]]               [328]                0       \n",
      "  Linear-148          [[328]]               [784]             257,936    \n",
      "  Sigmoid-21          [[784]]               [784]                0       \n",
      "===========================================================================\n",
      "Total params: 562,796\n",
      "Trainable params: 562,796\n",
      "Non-trainable params: 0\n",
      "---------------------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.02\n",
      "Params size (MB): 2.15\n",
      "Estimated Total Size (MB): 2.17\n",
      "---------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total_params': 562796, 'trainable_params': 562796}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = AutoEncoder1()\n",
    "model = paddle.Model(network)\n",
    "model.summary((784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle.regularizer as reg\n",
    "\n",
    "class AutoEncoder2(nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder2, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 328),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(328, 128),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, 12))\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(12, 32),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 328),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(328, 28 * 28),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "        # Add layer regularization\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        encoded = self.encoder(inputs)\n",
    "        decoded = self.decoder(encoded)\n",
    "\n",
    "        return encoded, decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      " Layer (type)       Input Shape          Output Shape         Param #    \n",
      "===========================================================================\n",
      "  Linear-206          [[784]]               [328]             257,480    \n",
      "   Dropout-1          [[328]]               [328]                0       \n",
      "   Tanh-149           [[328]]               [328]                0       \n",
      "  Linear-207          [[328]]               [128]             42,112     \n",
      "   Dropout-2          [[128]]               [128]                0       \n",
      "   Tanh-150           [[128]]               [128]                0       \n",
      "  Linear-208          [[128]]                [64]              8,256     \n",
      "   Dropout-3           [[64]]                [64]                0       \n",
      "   Tanh-151            [[64]]                [64]                0       \n",
      "  Linear-209           [[64]]                [32]              2,080     \n",
      "   Dropout-4           [[32]]                [32]                0       \n",
      "   Tanh-152            [[32]]                [32]                0       \n",
      "  Linear-210           [[32]]                [12]               396      \n",
      "  Linear-211           [[12]]                [32]               416      \n",
      "   Dropout-5           [[32]]                [32]                0       \n",
      "   Tanh-153            [[32]]                [32]                0       \n",
      "  Linear-212           [[32]]                [64]              2,112     \n",
      "   Dropout-6           [[64]]                [64]                0       \n",
      "   Tanh-154            [[64]]                [64]                0       \n",
      "  Linear-213           [[64]]               [128]              8,320     \n",
      "   Dropout-7          [[128]]               [128]                0       \n",
      "   Tanh-155           [[128]]               [128]                0       \n",
      "  Linear-214          [[128]]               [328]             42,312     \n",
      "   Dropout-8          [[328]]               [328]                0       \n",
      "   Tanh-156           [[328]]               [328]                0       \n",
      "  Linear-215          [[328]]               [784]             257,936    \n",
      "  Sigmoid-29          [[784]]               [784]                0       \n",
      "===========================================================================\n",
      "Total params: 621,420\n",
      "Trainable params: 621,420\n",
      "Non-trainable params: 0\n",
      "---------------------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.04\n",
      "Params size (MB): 2.37\n",
      "Estimated Total Size (MB): 2.41\n",
      "---------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total_params': 621420, 'trainable_params': 621420}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = AutoEncoder2()\n",
    "model = paddle.Model(network)\n",
    "model.summary((784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练配置\n",
    "paddle.framework.seed(1)\n",
    "EPOCH = 70\n",
    "LR = 0.0001\n",
    "N_TEST_IMG = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = paddle.optimizer.Adam(parameters=network.parameters(), learning_rate=LR)\n",
    "loss_func = nn.MSELoss()\n",
    "# loss_func = nn.functional.l1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练过程\n",
    "from visualdl import LogWriter\n",
    "logwriter = LogWriter(logdir=\"./run/auto0_3\")\n",
    "def train_auto1(model):\n",
    "    # 定义优化器\n",
    "    opt = paddle.optimizer.Adam(learning_rate=LR, parameters=model.parameters())\n",
    "    # 训练参数\n",
    "    iter = 0\n",
    "    iter2 = 0\n",
    "    for epoch_id in range(EPOCH):\n",
    "        total_test_accuracy = 0  # 用于累积测试准确率\n",
    "        for batch_id, data in enumerate(train_loader()):\n",
    "            model.train()\n",
    "            # 数据准备\n",
    "            images, labels = data\n",
    "            images = images.reshape((-1, 28 * 28))\n",
    "            images = paddle.to_tensor(images)\n",
    "            labels = paddle.reshape(labels, (-1,1))\n",
    "            labels = paddle.to_tensor(labels)\n",
    "            \n",
    "            # 前向\n",
    "            encoded, decoded = model(images)\n",
    "            \n",
    "            # 损失\n",
    "            loss = loss_func(decoded, images)\n",
    "            avg_loss= paddle.mean(loss)\n",
    "            if batch_id%200 ==  0:\n",
    "                print(\"epoch: {}, batch: {}, loss is: {}\".format(epoch_id, batch_id, avg_loss.numpy()))\n",
    "                logwriter.add_scalar(tag = 'train/loss' , step = iter, value=avg_loss.numpy())\n",
    "                iter+=200\n",
    "                \n",
    "            # 反向传播\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.clear_grad()\n",
    "\n",
    "\n",
    "        for batch_id, data in enumerate(test_loader()):\n",
    "            model.eval()\n",
    "            images, labels = data\n",
    "            images = images.reshape((-1, 28 * 28))\n",
    "            images = paddle.to_tensor(images)\n",
    "            labels = paddle.reshape(labels,(-1,1))\n",
    "            labels = paddle.to_tensor(labels)\n",
    "\n",
    "            # 预测\n",
    "            encoded, decoded = model(images)\n",
    "            # 损失\n",
    "            loss = loss_func(decoded, images)\n",
    "            avg_loss= paddle.mean(loss)\n",
    "\n",
    "            if batch_id % 100 == 0:\n",
    "                logwriter.add_scalar(tag='test/loss', step=iter2, value=avg_loss.numpy())\n",
    "                iter2+=100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch: 0, loss is: [1.9198976]\n",
      "epoch: 0, batch: 200, loss is: [0.9278727]\n",
      "epoch: 0, batch: 400, loss is: [0.9278425]\n",
      "epoch: 1, batch: 0, loss is: [0.92696536]\n",
      "epoch: 1, batch: 200, loss is: [0.9266324]\n",
      "epoch: 1, batch: 400, loss is: [0.92305815]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [71]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoEncoder()\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrain_auto1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [70]\u001b[0m, in \u001b[0;36mtrain_auto1\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     39\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     40\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m---> 41\u001b[0m images \u001b[38;5;241m=\u001b[39m \u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m images \u001b[38;5;241m=\u001b[39m paddle\u001b[38;5;241m.\u001b[39mto_tensor(images)\n\u001b[0;32m     43\u001b[0m labels \u001b[38;5;241m=\u001b[39m paddle\u001b[38;5;241m.\u001b[39mreshape(labels,(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32me:\\SoftWare\\Program\\Anaconda\\envs\\d2l\\lib\\site-packages\\paddle\\tensor\\manipulation.py:3588\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(x, shape, name)\u001b[0m\n\u001b[0;32m   3586\u001b[0m         out \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m   3587\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3588\u001b[0m         out \u001b[38;5;241m=\u001b[39m \u001b[43m_C_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3589\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(shape, core\u001b[38;5;241m.\u001b[39meager\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m   3590\u001b[0m     shape\u001b[38;5;241m.\u001b[39mstop_gradient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = AutoEncoder()\n",
    "train_auto1(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练过程\n",
    "from visualdl import LogWriter\n",
    "logwriter = LogWriter(logdir=\"./run/auto1_3_drop\")\n",
    "def train_auto1(model):\n",
    "    # 定义优化器\n",
    "    opt = paddle.optimizer.Adam(learning_rate=LR, parameters=model.parameters(), weight_decay=0.001)\n",
    "    # 训练参数\n",
    "    iter = 0\n",
    "    iter2 = 0\n",
    "    for epoch_id in range(EPOCH):\n",
    "        total_test_accuracy = 0  # 用于累积测试准确率\n",
    "        for batch_id, data in enumerate(train_loader()):\n",
    "            model.train()\n",
    "            # 数据准备\n",
    "            images, labels = data\n",
    "            images = images.reshape((-1, 28 * 28))\n",
    "            images = paddle.to_tensor(images)\n",
    "            labels = paddle.reshape(labels, (-1,1))\n",
    "            labels = paddle.to_tensor(labels)\n",
    "            \n",
    "            # 前向\n",
    "            encoded, decoded = model(images)\n",
    "            \n",
    "            # 损失\n",
    "            loss = loss_func(decoded, images)\n",
    "            avg_loss= paddle.mean(loss)\n",
    "            if batch_id%200 ==  0:\n",
    "                print(\"epoch: {}, batch: {}, loss is: {}\".format(epoch_id, batch_id, avg_loss.numpy()))\n",
    "                logwriter.add_scalar(tag = 'train/loss' , step = iter, value=avg_loss.numpy())\n",
    "                iter+=200\n",
    "                \n",
    "            # 反向传播\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.clear_grad()\n",
    "\n",
    "\n",
    "        for batch_id, data in enumerate(test_loader()):\n",
    "            model.eval()\n",
    "            images, labels = data\n",
    "            images = images.reshape((-1, 28 * 28))\n",
    "            images = paddle.to_tensor(images)\n",
    "            labels = paddle.reshape(labels,(-1,1))\n",
    "            labels = paddle.to_tensor(labels)\n",
    "\n",
    "            # 预测\n",
    "            encoded, decoded = model(images)\n",
    "            # 损失\n",
    "            loss = loss_func(decoded, images)\n",
    "            avg_loss= paddle.mean(loss)\n",
    "\n",
    "            if batch_id % 100 == 0:\n",
    "                logwriter.add_scalar(tag='test/loss', step=iter2, value=avg_loss.numpy())\n",
    "                iter2+=100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch: 0, loss is: [1.9136407]\n",
      "epoch: 0, batch: 200, loss is: [0.96415436]\n",
      "epoch: 0, batch: 400, loss is: [0.95010996]\n",
      "epoch: 1, batch: 0, loss is: [0.94511175]\n",
      "epoch: 1, batch: 200, loss is: [0.94769216]\n",
      "epoch: 1, batch: 400, loss is: [0.9421913]\n",
      "epoch: 2, batch: 0, loss is: [0.9419659]\n",
      "epoch: 2, batch: 200, loss is: [0.9422342]\n",
      "epoch: 2, batch: 400, loss is: [0.9409841]\n",
      "epoch: 3, batch: 0, loss is: [0.9428327]\n",
      "epoch: 3, batch: 200, loss is: [0.9377246]\n",
      "epoch: 3, batch: 400, loss is: [0.94115424]\n",
      "epoch: 4, batch: 0, loss is: [0.9417196]\n",
      "epoch: 4, batch: 200, loss is: [0.9404758]\n",
      "epoch: 4, batch: 400, loss is: [0.94213396]\n",
      "epoch: 5, batch: 0, loss is: [0.9386028]\n",
      "epoch: 5, batch: 200, loss is: [0.93943727]\n",
      "epoch: 5, batch: 400, loss is: [0.9403819]\n",
      "epoch: 6, batch: 0, loss is: [0.9407548]\n",
      "epoch: 6, batch: 200, loss is: [0.94175196]\n",
      "epoch: 6, batch: 400, loss is: [0.9375988]\n",
      "epoch: 7, batch: 0, loss is: [0.94094414]\n",
      "epoch: 7, batch: 200, loss is: [0.9372932]\n",
      "epoch: 7, batch: 400, loss is: [0.9345895]\n",
      "epoch: 8, batch: 0, loss is: [0.9429728]\n",
      "epoch: 8, batch: 200, loss is: [0.93718994]\n",
      "epoch: 8, batch: 400, loss is: [0.9359485]\n",
      "epoch: 9, batch: 0, loss is: [0.93999684]\n",
      "epoch: 9, batch: 200, loss is: [0.93827105]\n",
      "epoch: 9, batch: 400, loss is: [0.9395933]\n",
      "epoch: 10, batch: 0, loss is: [0.93912745]\n",
      "epoch: 10, batch: 200, loss is: [0.93856835]\n",
      "epoch: 10, batch: 400, loss is: [0.9375929]\n",
      "epoch: 11, batch: 0, loss is: [0.9396814]\n",
      "epoch: 11, batch: 200, loss is: [0.93930805]\n",
      "epoch: 11, batch: 400, loss is: [0.9410968]\n",
      "epoch: 12, batch: 0, loss is: [0.93674684]\n",
      "epoch: 12, batch: 200, loss is: [0.9434415]\n",
      "epoch: 12, batch: 400, loss is: [0.93882775]\n",
      "epoch: 13, batch: 0, loss is: [0.93912834]\n",
      "epoch: 13, batch: 200, loss is: [0.9367328]\n",
      "epoch: 13, batch: 400, loss is: [0.94061065]\n",
      "epoch: 14, batch: 0, loss is: [0.93875086]\n",
      "epoch: 14, batch: 200, loss is: [0.9414982]\n",
      "epoch: 14, batch: 400, loss is: [0.9377794]\n",
      "epoch: 15, batch: 0, loss is: [0.93754125]\n",
      "epoch: 15, batch: 200, loss is: [0.9404306]\n",
      "epoch: 15, batch: 400, loss is: [0.94048]\n",
      "epoch: 16, batch: 0, loss is: [0.94555914]\n",
      "epoch: 16, batch: 200, loss is: [0.94072694]\n",
      "epoch: 16, batch: 400, loss is: [0.94076586]\n",
      "epoch: 17, batch: 0, loss is: [0.93608797]\n",
      "epoch: 17, batch: 200, loss is: [0.93843687]\n",
      "epoch: 17, batch: 400, loss is: [0.9399956]\n",
      "epoch: 18, batch: 0, loss is: [0.9401574]\n",
      "epoch: 18, batch: 200, loss is: [0.939921]\n",
      "epoch: 18, batch: 400, loss is: [0.9401673]\n",
      "epoch: 19, batch: 0, loss is: [0.9368628]\n",
      "epoch: 19, batch: 200, loss is: [0.9413467]\n",
      "epoch: 19, batch: 400, loss is: [0.93837357]\n",
      "epoch: 20, batch: 0, loss is: [0.9406613]\n",
      "epoch: 20, batch: 200, loss is: [0.9424102]\n",
      "epoch: 20, batch: 400, loss is: [0.94163203]\n",
      "epoch: 21, batch: 0, loss is: [0.9394321]\n",
      "epoch: 21, batch: 200, loss is: [0.9395131]\n",
      "epoch: 21, batch: 400, loss is: [0.93944645]\n",
      "epoch: 22, batch: 0, loss is: [0.93973565]\n",
      "epoch: 22, batch: 200, loss is: [0.93924415]\n",
      "epoch: 22, batch: 400, loss is: [0.94144017]\n",
      "epoch: 23, batch: 0, loss is: [0.9397011]\n",
      "epoch: 23, batch: 200, loss is: [0.9378804]\n",
      "epoch: 23, batch: 400, loss is: [0.9370794]\n",
      "epoch: 24, batch: 0, loss is: [0.94180715]\n",
      "epoch: 24, batch: 200, loss is: [0.9395376]\n",
      "epoch: 24, batch: 400, loss is: [0.9416622]\n",
      "epoch: 25, batch: 0, loss is: [0.9392727]\n",
      "epoch: 25, batch: 200, loss is: [0.9442479]\n",
      "epoch: 25, batch: 400, loss is: [0.9429606]\n",
      "epoch: 26, batch: 0, loss is: [0.9399109]\n",
      "epoch: 26, batch: 200, loss is: [0.9346551]\n",
      "epoch: 26, batch: 400, loss is: [0.93688047]\n",
      "epoch: 27, batch: 0, loss is: [0.94329494]\n",
      "epoch: 27, batch: 200, loss is: [0.9367151]\n",
      "epoch: 27, batch: 400, loss is: [0.9430039]\n",
      "epoch: 28, batch: 0, loss is: [0.9401376]\n",
      "epoch: 28, batch: 200, loss is: [0.93782854]\n",
      "epoch: 28, batch: 400, loss is: [0.9393141]\n",
      "epoch: 29, batch: 0, loss is: [0.94175446]\n",
      "epoch: 29, batch: 200, loss is: [0.9373318]\n",
      "epoch: 29, batch: 400, loss is: [0.9367585]\n",
      "epoch: 30, batch: 0, loss is: [0.9395536]\n",
      "epoch: 30, batch: 200, loss is: [0.93748206]\n",
      "epoch: 30, batch: 400, loss is: [0.9420004]\n",
      "epoch: 31, batch: 0, loss is: [0.9424957]\n",
      "epoch: 31, batch: 200, loss is: [0.94059634]\n",
      "epoch: 31, batch: 400, loss is: [0.94112444]\n",
      "epoch: 32, batch: 0, loss is: [0.9374635]\n",
      "epoch: 32, batch: 200, loss is: [0.9415689]\n",
      "epoch: 32, batch: 400, loss is: [0.9404967]\n",
      "epoch: 33, batch: 0, loss is: [0.9400609]\n",
      "epoch: 33, batch: 200, loss is: [0.94258493]\n",
      "epoch: 33, batch: 400, loss is: [0.93833554]\n",
      "epoch: 34, batch: 0, loss is: [0.9376135]\n",
      "epoch: 34, batch: 200, loss is: [0.9384535]\n",
      "epoch: 34, batch: 400, loss is: [0.94155777]\n",
      "epoch: 35, batch: 0, loss is: [0.9431132]\n",
      "epoch: 35, batch: 200, loss is: [0.9359977]\n",
      "epoch: 35, batch: 400, loss is: [0.9403333]\n",
      "epoch: 36, batch: 0, loss is: [0.94011676]\n",
      "epoch: 36, batch: 200, loss is: [0.93799436]\n",
      "epoch: 36, batch: 400, loss is: [0.93829274]\n",
      "epoch: 37, batch: 0, loss is: [0.94057995]\n",
      "epoch: 37, batch: 200, loss is: [0.9405148]\n",
      "epoch: 37, batch: 400, loss is: [0.9420579]\n",
      "epoch: 38, batch: 0, loss is: [0.93831456]\n",
      "epoch: 38, batch: 200, loss is: [0.9429599]\n",
      "epoch: 38, batch: 400, loss is: [0.9419738]\n",
      "epoch: 39, batch: 0, loss is: [0.94184786]\n",
      "epoch: 39, batch: 200, loss is: [0.9396333]\n",
      "epoch: 39, batch: 400, loss is: [0.94086856]\n",
      "epoch: 40, batch: 0, loss is: [0.93888414]\n",
      "epoch: 40, batch: 200, loss is: [0.94432914]\n",
      "epoch: 40, batch: 400, loss is: [0.9395777]\n",
      "epoch: 41, batch: 0, loss is: [0.9436053]\n",
      "epoch: 41, batch: 200, loss is: [0.9409254]\n",
      "epoch: 41, batch: 400, loss is: [0.9380317]\n",
      "epoch: 42, batch: 0, loss is: [0.9356924]\n",
      "epoch: 42, batch: 200, loss is: [0.9393061]\n",
      "epoch: 42, batch: 400, loss is: [0.9383898]\n",
      "epoch: 43, batch: 0, loss is: [0.9375372]\n",
      "epoch: 43, batch: 200, loss is: [0.94153917]\n",
      "epoch: 43, batch: 400, loss is: [0.94023395]\n",
      "epoch: 44, batch: 0, loss is: [0.93876463]\n",
      "epoch: 44, batch: 200, loss is: [0.9416919]\n",
      "epoch: 44, batch: 400, loss is: [0.93632257]\n",
      "epoch: 45, batch: 0, loss is: [0.9394207]\n",
      "epoch: 45, batch: 200, loss is: [0.9435371]\n",
      "epoch: 45, batch: 400, loss is: [0.93677783]\n",
      "epoch: 46, batch: 0, loss is: [0.93619573]\n",
      "epoch: 46, batch: 200, loss is: [0.93965566]\n",
      "epoch: 46, batch: 400, loss is: [0.9396908]\n",
      "epoch: 47, batch: 0, loss is: [0.9419334]\n",
      "epoch: 47, batch: 200, loss is: [0.9423574]\n",
      "epoch: 47, batch: 400, loss is: [0.93884903]\n",
      "epoch: 48, batch: 0, loss is: [0.9344598]\n",
      "epoch: 48, batch: 200, loss is: [0.9372517]\n",
      "epoch: 48, batch: 400, loss is: [0.941866]\n",
      "epoch: 49, batch: 0, loss is: [0.9401991]\n",
      "epoch: 49, batch: 200, loss is: [0.93739486]\n",
      "epoch: 49, batch: 400, loss is: [0.9383203]\n",
      "epoch: 50, batch: 0, loss is: [0.93852854]\n",
      "epoch: 50, batch: 200, loss is: [0.93895274]\n",
      "epoch: 50, batch: 400, loss is: [0.94118667]\n",
      "epoch: 51, batch: 0, loss is: [0.9431977]\n",
      "epoch: 51, batch: 200, loss is: [0.93928623]\n",
      "epoch: 51, batch: 400, loss is: [0.93888485]\n",
      "epoch: 52, batch: 0, loss is: [0.941924]\n",
      "epoch: 52, batch: 200, loss is: [0.94267213]\n",
      "epoch: 52, batch: 400, loss is: [0.9374602]\n",
      "epoch: 53, batch: 0, loss is: [0.941741]\n",
      "epoch: 53, batch: 200, loss is: [0.94102144]\n",
      "epoch: 53, batch: 400, loss is: [0.93958235]\n",
      "epoch: 54, batch: 0, loss is: [0.93826485]\n",
      "epoch: 54, batch: 200, loss is: [0.94057685]\n",
      "epoch: 54, batch: 400, loss is: [0.941133]\n",
      "epoch: 55, batch: 0, loss is: [0.94075286]\n",
      "epoch: 55, batch: 200, loss is: [0.93923175]\n",
      "epoch: 55, batch: 400, loss is: [0.9413306]\n",
      "epoch: 56, batch: 0, loss is: [0.94108146]\n",
      "epoch: 56, batch: 200, loss is: [0.94144565]\n",
      "epoch: 56, batch: 400, loss is: [0.93852496]\n",
      "epoch: 57, batch: 0, loss is: [0.93813604]\n",
      "epoch: 57, batch: 200, loss is: [0.9370644]\n",
      "epoch: 57, batch: 400, loss is: [0.9402953]\n",
      "epoch: 58, batch: 0, loss is: [0.9401864]\n",
      "epoch: 58, batch: 200, loss is: [0.93941224]\n",
      "epoch: 58, batch: 400, loss is: [0.9392276]\n",
      "epoch: 59, batch: 0, loss is: [0.93887687]\n",
      "epoch: 59, batch: 200, loss is: [0.939729]\n",
      "epoch: 59, batch: 400, loss is: [0.9406158]\n",
      "epoch: 60, batch: 0, loss is: [0.9376936]\n",
      "epoch: 60, batch: 200, loss is: [0.9399414]\n",
      "epoch: 60, batch: 400, loss is: [0.93900067]\n",
      "epoch: 61, batch: 0, loss is: [0.9408728]\n",
      "epoch: 61, batch: 200, loss is: [0.9397937]\n",
      "epoch: 61, batch: 400, loss is: [0.9407414]\n",
      "epoch: 62, batch: 0, loss is: [0.9410261]\n",
      "epoch: 62, batch: 200, loss is: [0.9429797]\n",
      "epoch: 62, batch: 400, loss is: [0.9392736]\n",
      "epoch: 63, batch: 0, loss is: [0.94012487]\n",
      "epoch: 63, batch: 200, loss is: [0.9388648]\n",
      "epoch: 63, batch: 400, loss is: [0.93914646]\n",
      "epoch: 64, batch: 0, loss is: [0.93996584]\n",
      "epoch: 64, batch: 200, loss is: [0.93835056]\n",
      "epoch: 64, batch: 400, loss is: [0.93744874]\n",
      "epoch: 65, batch: 0, loss is: [0.9386704]\n",
      "epoch: 65, batch: 200, loss is: [0.9401392]\n",
      "epoch: 65, batch: 400, loss is: [0.9385861]\n",
      "epoch: 66, batch: 0, loss is: [0.94243395]\n",
      "epoch: 66, batch: 200, loss is: [0.94003403]\n",
      "epoch: 66, batch: 400, loss is: [0.9393158]\n",
      "epoch: 67, batch: 0, loss is: [0.94069135]\n",
      "epoch: 67, batch: 200, loss is: [0.9420799]\n",
      "epoch: 67, batch: 400, loss is: [0.93730915]\n",
      "epoch: 68, batch: 0, loss is: [0.9400209]\n",
      "epoch: 68, batch: 200, loss is: [0.9406521]\n",
      "epoch: 68, batch: 400, loss is: [0.93738]\n",
      "epoch: 69, batch: 0, loss is: [0.9406699]\n",
      "epoch: 69, batch: 200, loss is: [0.94041526]\n",
      "epoch: 69, batch: 400, loss is: [0.940184]\n"
     ]
    }
   ],
   "source": [
    "model = AutoEncoder2()\n",
    "train_auto1(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5 | train loss: 0.9410\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m train_x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape([\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m28\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m28\u001b[39m])\n\u001b[0;32m     10\u001b[0m encoded, decoded \u001b[38;5;241m=\u001b[39m network(train_x)\n\u001b[1;32m---> 11\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     13\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32me:\\SoftWare\\Program\\Anaconda\\envs\\d2l\\lib\\site-packages\\paddle\\nn\\layer\\layers.py:1254\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1246\u001b[0m     (\u001b[38;5;129;01mnot\u001b[39;00m in_declarative_mode())\n\u001b[0;32m   1247\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1251\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m in_profiler_mode())\n\u001b[0;32m   1252\u001b[0m ):\n\u001b[0;32m   1253\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_once(\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 1254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1255\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1256\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dygraph_call_func(\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\SoftWare\\Program\\Anaconda\\envs\\d2l\\lib\\site-packages\\paddle\\nn\\layer\\loss.py:590\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[1;34m(self, input, label)\u001b[0m\n\u001b[0;32m    585\u001b[0m     fluid\u001b[38;5;241m.\u001b[39mdata_feeder\u001b[38;5;241m.\u001b[39mcheck_variable_and_dtype(\n\u001b[0;32m    586\u001b[0m         label, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMSELoss\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    587\u001b[0m     )\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m in_dygraph_mode():\n\u001b[1;32m--> 590\u001b[0m     square_out \u001b[38;5;241m=\u001b[39m \u001b[43mpaddle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msquare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpaddle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubtract\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    592\u001b[0m     square_out \u001b[38;5;241m=\u001b[39m paddle\u001b[38;5;241m.\u001b[39msquare(paddle\u001b[38;5;241m.\u001b[39msubtract(\u001b[38;5;28minput\u001b[39m, label))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "view_data = np.array([np.array(mnist[i][0]) / 255.0 for i in range(N_TEST_IMG)]).reshape(-1, 28 * 28).astype('float32')\n",
    "\n",
    "step_loss_list = []\n",
    "decoded_img_list = []\n",
    "epoch_loss_list = []\n",
    "network.train()\n",
    "for epoch in range(EPOCH):\n",
    "    for x, _ in train_loader:\n",
    "        train_x = x.reshape([-1, 28 * 28])\n",
    "        encoded, decoded = network(train_x)\n",
    "        loss = loss_func(decoded, train_x)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.clear_grad()\n",
    "        step_loss_list.append(loss.numpy())\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print('Epoch: %2d' % (epoch + 1), '| train loss: %.4f' % np.mean(step_loss_list))\n",
    "    epoch_loss_list.append(np.mean(step_loss_list))\n",
    "    _, decoded_data = network(paddle.to_tensor(view_data))\n",
    "    decoded_img_list.append(decoded_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.gcf()\n",
    "fig.set_size_inches(10, 5)\n",
    "plt.plot(epoch_loss_list, color=(1, 0, 0))\n",
    "plt.title('Autoencoder Training Value')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import cv2\n",
    "\n",
    "img_data = view_data\n",
    "concat_img = []\n",
    "black = np.zeros([28, 1])\n",
    "anim_file = 'assets/autoencoder.gif'\n",
    "\n",
    "img_raw = np.hstack((img_data[0].reshape(28, 28) * 255, black,\n",
    "                     img_data[1].reshape(28, 28) * 255, black,\n",
    "                     img_data[2].reshape(28, 28) * 255, black,\n",
    "                     img_data[3].reshape(28, 28) * 255, black,\n",
    "                     img_data[4].reshape(28, 28) * 255, black,\n",
    "                     img_data[5].reshape(28, 28) * 255, black,\n",
    "                     img_data[6].reshape(28, 28) * 255, black,\n",
    "                     img_data[7].reshape(28, 28) * 255, black,\n",
    "                     img_data[8].reshape(28, 28) * 255, black,\n",
    "                     img_data[9].reshape(28, 28) * 255)).astype('uint8')\n",
    "size = (int(img_raw.shape[1] * 2.4), int(img_raw.shape[0] * 2.4))\n",
    "img_raw = cv2.resize(img_raw, size)\n",
    "\n",
    "with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "    for i in range(len(decoded_img_list)):\n",
    "        img_decode = np.hstack((decoded_img_list[i].cpu().detach().numpy()[0].reshape(28, 28) * 255, black,\n",
    "                         decoded_img_list[i].cpu().detach().numpy()[1].reshape(28, 28) * 255, black,\n",
    "                         decoded_img_list[i].cpu().detach().numpy()[2].reshape(28, 28) * 255, black,\n",
    "                         decoded_img_list[i].cpu().detach().numpy()[3].reshape(28, 28) * 255, black,\n",
    "                         decoded_img_list[i].cpu().detach().numpy()[4].reshape(28, 28) * 255, black,\n",
    "                         decoded_img_list[i].cpu().detach().numpy()[5].reshape(28, 28) * 255, black,\n",
    "                         decoded_img_list[i].cpu().detach().numpy()[6].reshape(28, 28) * 255, black,\n",
    "                         decoded_img_list[i].cpu().detach().numpy()[7].reshape(28, 28) * 255, black,\n",
    "                         decoded_img_list[i].cpu().detach().numpy()[8].reshape(28, 28) * 255, black,\n",
    "                         decoded_img_list[i].cpu().detach().numpy()[9].reshape(28, 28) * 255)).astype('uint8')\n",
    "        img_decode = cv2.resize(img_decode, size)\n",
    "        img = np.vstack((img_raw, img_decode))\n",
    "        writer.append_data(img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "\n",
    "network.eval()\n",
    "view_data = np.array([np.array(mnist[i][0]) / 255.0 for i in range(5000)]).reshape(-1, 28 * 28).astype('float32')\n",
    "encoded_data, _ = network(paddle.to_tensor(view_data))\n",
    "fig = plt.figure(2)\n",
    "fig.set_size_inches(15, 15)\n",
    "ax = Axes3D(fig)\n",
    "X, Y, Z = encoded_data.numpy()[:, 0], encoded_data.numpy()[:, 1], encoded_data.numpy()[:, 2]\n",
    "values = [np.array(mnist[i][1]).item() for i in range(5000)]\n",
    "for x, y, z, s in zip(X, Y, Z, values):\n",
    "    c = cm.rainbow(int(255 * s / 9))\n",
    "    ax.text(x, y, z, s, backgroundcolor=c)\n",
    "ax.set_xlim(X.min(), X.max())\n",
    "ax.set_ylim(Y.min(), Y.max())\n",
    "ax.set_zlim(Z.min(), Z.max())\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
