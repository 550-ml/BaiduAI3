{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用集成学习，建立两个模型\n",
    "# 定义模型结构\n",
    "# 使用dropout\n",
    "\n",
    "import paddle.nn.functional as F\n",
    "from paddle.nn import Conv2D, MaxPool2D, Linear, BatchNorm2D\n",
    "# 一个加入比较好的\n",
    "class Cifar_TWO_CONV2_norm(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(Cifar_TWO_CONV2_norm, self).__init__()\n",
    "\n",
    "        # 定义一层卷积层\n",
    "        self.conv1 = Conv2D(in_channels=3, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
    "        # 定义批归一化层\n",
    "        self.bn1 = BatchNorm2D(32)\n",
    "        # 定义最大池化\n",
    "        self.max_pool1 = MaxPool2D(kernel_size=2, stride=2)\n",
    "        # 定义第二层卷积层\n",
    "        self.conv2 = Conv2D(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=2)\n",
    "        # 第二个批归一化层\n",
    "        self.bn2 = BatchNorm2D(64)\n",
    "        # 定义最大池化\n",
    "        self.max_pool2 = MaxPool2D(kernel_size=2, stride=2)\n",
    "        # 这样输出的就是20*16*16,定义一个全连接\n",
    "        self.fc = Linear(in_features=4096, out_features=10)\n",
    "\n",
    "    def forward(self, inputs, label, mode='upscale_in_train'):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.max_pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.max_pool2(x)\n",
    "        x = paddle.reshape(x, [x.shape[0], -1])\n",
    "        x = self.fc(x)\n",
    "\n",
    "        if label is not None:\n",
    "            acc = paddle.metric.accuracy(input=x, label = label)\n",
    "            return x, acc\n",
    "        else:\n",
    "            return x\n",
    "        \n",
    "\n",
    "class Cifar_TWO_CONV2_lenet(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(Cifar_TWO_CONV2_lenet, self).__init__()\n",
    "\n",
    "        # 定义一层卷积层\n",
    "        self.conv1 = Conv2D(in_channels=3, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
    "        # 定义批归一化层\n",
    "        self.bn1 = BatchNorm2D(32)\n",
    "        # 定义最大池化\n",
    "        self.max_pool1 = MaxPool2D(kernel_size=2, stride=2)\n",
    "        # 定义第二层卷积层\n",
    "        self.conv2 = Conv2D(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=2)\n",
    "        # 第二个批归一化层\n",
    "        self.bn2 = BatchNorm2D(64)\n",
    "        # 定义最大池化\n",
    "        self.max_pool2 = MaxPool2D(kernel_size=2, stride=2)\n",
    "        # 这样输出的就是20*16*16,定义一个全连接\n",
    "        self.fc1 = Linear(in_features=4096, out_features=2048)\n",
    "        self.fc2 = Linear(in_features=2048, out_features=1024)\n",
    "        self.fc3 = Linear(in_features=1024, out_features=10)\n",
    "\n",
    "    def forward(self, inputs, label, mode='upscale_in_train'):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.max_pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.max_pool2(x)\n",
    "        x = paddle.reshape(x, [x.shape[0], -1])\n",
    "        x = self.fc1(x)\n",
    "        x = F.dropout(x,p =0.1,mode=mode )\n",
    "        x = self.fc2(x)\n",
    "        x = F.dropout(x, p=0.1, mode=mode)\n",
    "        x = self.fc3(x)\n",
    "        if label is not None:\n",
    "            acc = paddle.metric.accuracy(input=x, label = label)\n",
    "            return x, acc\n",
    "        else:\n",
    "            return x\n",
    "use_gpu = True\n",
    "paddle.set_device('gpu:0') if use_gpu else paddle.set_device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练过程\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from visualdl import LogWriter\n",
    "from paddle.optimizer.lr import CosineAnnealingDecay\n",
    "from paddle.nn import BatchNorm2D\n",
    "\n",
    "logwriter = LogWriter(logdir=\"./run/cifar_log/two_conv_jicheng\")\n",
    "def train_Cifar_TWO2_norm_end():\n",
    "    # 初始化网络\n",
    "    net1 = Cifar_TWO_CONV2_lenet()\n",
    "    net1.train()\n",
    "    net2 = Cifar_TWO_CONV2_norm()\n",
    "    net_test = Cifar_ONE_CONV()\n",
    "    # 两个个模型放一起\n",
    "    mlps = [net1, net2]\n",
    "    opt1 = paddle.optimizer.Adam( learning_rate=0.01, parameters=net1.parameters())\n",
    "    opt2 = paddle.optimizer.Adam( learning_rate=0.01, parameters=net2.parameters())\n",
    "    opt = [opt1, opt2]\n",
    "    # 定义优化器\n",
    "    EPOCH_NUM = 15\n",
    "\n",
    "    # 训练参数\n",
    "    iter = 0\n",
    "    iter2 = 0\n",
    "    for epoch_id in range(EPOCH_NUM):\n",
    "        for batch_id, data in enumerate(train_loader()):\n",
    "            # 数据准备\n",
    "            images, labels = data\n",
    "            images = paddle.to_tensor(images)\n",
    "            labels = paddle.reshape(labels, (-1,1))\n",
    "            labels = paddle.to_tensor(labels)\n",
    "            for i, mlp in enumerate(mlps):\n",
    "                mlp.train()\n",
    "                # 前向\n",
    "                net_test.train()\n",
    "                predict,acc = net_test(images,labels)\n",
    "                net1.train()\n",
    "                predict,acc = net1(images,labels,mode='upscale_in_train')\n",
    "                predict, acc = mlp(images, labels)\n",
    "\n",
    "                # 损失\n",
    "                loss = F.cross_entropy(predict, labels)\n",
    "                avg_loss = paddle.mean(loss)\n",
    "\n",
    "                # 反向传播\n",
    "                avg_loss.backward()\n",
    "                opt[i].step()\n",
    "                opt[i].clear_grad()\n",
    "        pre=[]\n",
    "        vote_correct = 0\n",
    "        mlps_correct = [0 for i in range(len(mlps))]\n",
    "        for batch_id, data in enumerate(test_loader()):\n",
    "            images, labels = data\n",
    "            images = paddle.to_tensor(images)\n",
    "            labels = paddle.reshape(labels,(-1,1))\n",
    "            labels = paddle.to_tensor(labels)\n",
    "            for i, mlp in enumerate(mlps):\n",
    "                mlp.eval()\n",
    "                \n",
    "                # 预测\n",
    "                predicts, acc = mlp(images, labels,mode='downscale_in_infer')\n",
    "                _, prediction = paddle.max(predicts,1)\n",
    "                pre_num = prediction.numpy()\n",
    "                mlps_correct[i] +=(pre_num==labels.numpy()).sum\n",
    "                pre.append(pre_num)\n",
    "            arr = np.array(pre)\n",
    "            pre.clear()\n",
    "            result = [Counter(arr[:, i]).most_common(1)[0][0] for i in range(128)]\n",
    "            vote_correct += (result == labels.numpy()).sum()\n",
    "\n",
    "        print(\"epoch:\" + str(epoch_id) + \"集成模型的正确率\" + str(vote_correct / len(test_loader)))\n",
    " \n",
    "        for idx, coreect in enumerate(mlps_correct):\n",
    "            print(\"模型\" + str(idx) + \"的正确率为：\" + str(coreect / len(test_loader)))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
