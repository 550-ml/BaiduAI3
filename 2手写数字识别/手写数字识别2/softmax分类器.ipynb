{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用的框架paddle\n",
    "# 相关框架的加载\n",
    "import paddle\n",
    "from paddle.nn import Linear\n",
    "import paddle.nn.functional as F\n",
    "import os\n",
    "import gzip\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from visualdl import LogWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "from paddle.vision.transforms import Normalize\n",
    "\n",
    "def get_MNIST_dataloader():\n",
    "    # 定义图像归一化处理方法，这里的CHW指图像格式需为 [C通道数，H图像高度，W图像宽度]\n",
    "    transform = Normalize(mean=[127.5], std=[127.5], data_format='CHW')\n",
    "    # 下载数据集并初始化 DataSet\n",
    "    train_dataset = paddle.vision.datasets.MNIST(mode='train', transform=transform)\n",
    "    test_dataset = paddle.vision.datasets.MNIST(mode='test', transform=transform)\n",
    "\n",
    "    # 定义并初始化数据读取器\n",
    "    train_loader = paddle.io.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=1, drop_last=True)\n",
    "    test_loader = paddle.io.DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=1, drop_last=False)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\SoftWare\\Program\\Anaconda\\envs\\d2l\\lib\\site-packages\\paddle\\io\\reader.py:433: UserWarning: DataLoader with multi-process mode is not supported on MacOs and Windows currently. Please use signle-process mode with num_workers = 0 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = get_MNIST_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SOFTMAX_NET(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(SOFTMAX_NET, self).__init__()\n",
    "        self.fc1 = Linear(in_features=784, out_features=10)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        inputs = paddle.reshape(inputs, [inputs.shape[0], 784])\n",
    "        outputs1 = self.fc1(inputs)\n",
    "        outputs_final = F.softmax(outputs1)\n",
    "        return outputs_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据载入\n",
    "logwriter = LogWriter(logdir='./log')\n",
    "class MNISTDataset():\n",
    "  def __init__(self, mode='train'):\n",
    "    self.mnist_data = paddle.vision.datasets.MNIST(mode=mode)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    data, label = self.mnist_data[idx]\n",
    "    data = np.reshape(data, [1, 28, 28]).astype('float32') / 255\n",
    "    label = np.reshape(label, [1]).astype('int64')\n",
    "    return (data, label)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.mnist_data)\n",
    "\n",
    "# 查看 9 张输入的训练图像的样例\n",
    "dataset = MNISTDataset(mode='train')\n",
    "image_matrix = []\n",
    "for i in range(9):\n",
    "  image, label = dataset[i]\n",
    "  # 将 dataset 中的 CHW 排列的图像转换成 HWC 排列再写入 VisualDL\n",
    "  image_matrix.append(image.transpose([1,2,0]))\n",
    "# 将九张输入图像合成长宽相同的图像网格，即 3X3 的图像网格\n",
    "logwriter.add_image_matrix(tag='input_images', step=1, imgs=image_matrix, rows=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    model.train()\n",
    "    train_batchs_per_epoch = len(train_loader)\n",
    "    # 训练参数\n",
    "    opt = paddle.optimizer.SGD(learning_rate=0.05, parameters=model.parameters())\n",
    "    EPOCH_NUM = 10\n",
    "    losses = []\n",
    "    acc_test = []\n",
    "    losses_test = []\n",
    "    # 训练\n",
    "    for epoch_id in range(EPOCH_NUM):\n",
    "        for batch_id, data in enumerate(train_loader()):\n",
    "            # 数据准备\n",
    "            images, labels = data\n",
    "            images = paddle.to_tensor(images)\n",
    "            labels = paddle.to_tensor(labels)\n",
    "\n",
    "            # 前向训练\n",
    "            predicts = model(images)\n",
    "\n",
    "            # 交叉熵损失\n",
    "            loss = F.cross_entropy(predicts, labels)\n",
    "            avg_loss = paddle.mean(loss)\n",
    "\n",
    "            #记录当前训练 Loss 到 VisualDL\n",
    "            logwriter.add_scalar(\"train_avg_loss\", value=avg_loss.numpy(), step=batch_id+epoch_id*(train_batchs_per_epoch))\n",
    "\n",
    "            #每训练200批次的数据，打印下当前Loss的情况\n",
    "            if batch_id % 200 == 0:\n",
    "                losses.append(avg_loss.numpy()[0])\n",
    "                print(\"epoch: {}, batch: {}, loss is: {}\".format(epoch_id, batch_id, avg_loss.numpy()))\n",
    "            \n",
    "            # 反向\n",
    "            avg_loss.backward()\n",
    "            opt.step()\n",
    "            opt.clear_grad()\n",
    "        \n",
    "        for batch_id, data in enumerate(test_loader()):\n",
    "            model.eval()\n",
    "            images, labels = data\n",
    "            images = paddle.to_tensor(images)\n",
    "            labels = paddle.to_tensor(labels)\n",
    "\n",
    "            predicts = model(images)\n",
    "\n",
    "            loss = F.cross_entropy(predicts, labels)\n",
    "            acc = paddle.metric.accuracy(predicts, labels)\n",
    "\n",
    "            acc_test.append(acc.numpy())\n",
    "            losses_test.append(loss)\n",
    "        test_avg_loss = np.mean(losses_test)\n",
    "        test_avg_acc = np.mean(acc_test)\n",
    "        print(\"[validation]After epoch {}: accuracy/loss: {}/{}\".format(epoch_id,test_avg_acc , test_avg_acc))\n",
    "        logwriter.add_scalar(\"test_avg_loss\", value=test_avg_loss, step=epoch_id)\n",
    "        logwriter.add_scalar(\"test_avg_acc\", value=test_avg_acc, step=epoch_id)\n",
    "\n",
    "\n",
    "    paddle.save(model.state_dict(), 'mnist_softmax.pdparams')\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\SoftWare\\Program\\Anaconda\\envs\\d2l\\lib\\site-packages\\paddle\\fluid\\variable_index.py:591: UserWarning: Warning: In Tensor '__getitem__', if the number of scalar elements in the index is equal to the rank of the Tensor, the output should be 0-D. In order to be consistent with the behavior of previous versions, it will be processed to 1-D. But it is not correct and will be removed in release 2.6. If 1-D is still wanted, please modify the index element from scalar to slice (e.g. 'x[i]' => 'x[i:i+1]').\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch: 0, loss is: [2.3194082]\n",
      "epoch: 0, batch: 200, loss is: [1.8708612]\n",
      "epoch: 0, batch: 400, loss is: [1.882052]\n",
      "epoch: 0, batch: 600, loss is: [1.8606933]\n",
      "epoch: 0, batch: 800, loss is: [1.7190285]\n",
      "[validation]After epoch 0: accuracy/loss: 0.6634156107902527/0.6634156107902527\n",
      "epoch: 1, batch: 0, loss is: [1.7031863]\n",
      "epoch: 1, batch: 200, loss is: [1.7168865]\n",
      "epoch: 1, batch: 400, loss is: [1.8453493]\n",
      "epoch: 1, batch: 600, loss is: [1.7943172]\n",
      "epoch: 1, batch: 800, loss is: [1.7291168]\n",
      "[validation]After epoch 1: accuracy/loss: 0.7030752301216125/0.7030752301216125\n",
      "epoch: 2, batch: 0, loss is: [1.7218847]\n",
      "epoch: 2, batch: 200, loss is: [1.6757426]\n",
      "epoch: 2, batch: 400, loss is: [1.6252906]\n",
      "epoch: 2, batch: 600, loss is: [1.6606683]\n",
      "epoch: 2, batch: 800, loss is: [1.6534338]\n",
      "[validation]After epoch 2: accuracy/loss: 0.7413747310638428/0.7413747310638428\n",
      "epoch: 3, batch: 0, loss is: [1.7231197]\n",
      "epoch: 3, batch: 200, loss is: [1.6592734]\n",
      "epoch: 3, batch: 400, loss is: [1.7204098]\n",
      "epoch: 3, batch: 600, loss is: [1.6334673]\n",
      "epoch: 3, batch: 800, loss is: [1.7067506]\n",
      "[validation]After epoch 3: accuracy/loss: 0.7623158693313599/0.7623158693313599\n",
      "epoch: 4, batch: 0, loss is: [1.6781485]\n",
      "epoch: 4, batch: 200, loss is: [1.6901877]\n",
      "epoch: 4, batch: 400, loss is: [1.6441463]\n",
      "epoch: 4, batch: 600, loss is: [1.7053967]\n",
      "epoch: 4, batch: 800, loss is: [1.7270994]\n",
      "[validation]After epoch 4: accuracy/loss: 0.7752985954284668/0.7752985954284668\n",
      "epoch: 5, batch: 0, loss is: [1.7144706]\n",
      "epoch: 5, batch: 200, loss is: [1.5846593]\n",
      "epoch: 5, batch: 400, loss is: [1.6148809]\n",
      "epoch: 5, batch: 600, loss is: [1.6722215]\n",
      "epoch: 5, batch: 800, loss is: [1.6236081]\n",
      "[validation]After epoch 5: accuracy/loss: 0.784401535987854/0.784401535987854\n",
      "epoch: 6, batch: 0, loss is: [1.7200775]\n",
      "epoch: 6, batch: 200, loss is: [1.6342396]\n",
      "epoch: 6, batch: 400, loss is: [1.5850573]\n",
      "epoch: 6, batch: 600, loss is: [1.6054989]\n",
      "epoch: 6, batch: 800, loss is: [1.6204236]\n",
      "[validation]After epoch 6: accuracy/loss: 0.7912022471427917/0.7912022471427917\n",
      "epoch: 7, batch: 0, loss is: [1.7304171]\n",
      "epoch: 7, batch: 200, loss is: [1.6236771]\n",
      "epoch: 7, batch: 400, loss is: [1.5919564]\n",
      "epoch: 7, batch: 600, loss is: [1.585729]\n",
      "epoch: 7, batch: 800, loss is: [1.5750299]\n",
      "[validation]After epoch 7: accuracy/loss: 0.7965764403343201/0.7965764403343201\n",
      "epoch: 8, batch: 0, loss is: [1.5989584]\n",
      "epoch: 8, batch: 200, loss is: [1.6346022]\n",
      "epoch: 8, batch: 400, loss is: [1.5953282]\n",
      "epoch: 8, batch: 600, loss is: [1.6491208]\n",
      "epoch: 8, batch: 800, loss is: [1.6357089]\n",
      "[validation]After epoch 8: accuracy/loss: 0.8005462884902954/0.8005462884902954\n",
      "epoch: 9, batch: 0, loss is: [1.5718454]\n",
      "epoch: 9, batch: 200, loss is: [1.6132756]\n",
      "epoch: 9, batch: 400, loss is: [1.6441113]\n",
      "epoch: 9, batch: 600, loss is: [1.6875358]\n",
      "epoch: 9, batch: 800, loss is: [1.7076762]\n",
      "[validation]After epoch 9: accuracy/loss: 0.8039211630821228/0.8039211630821228\n"
     ]
    }
   ],
   "source": [
    "model_softmax = SOFTMAX_NET()\n",
    "# 网络结构\n",
    "paddle.jit.save(model_softmax, './mnist_softmax.pdparams', [paddle.static.InputSpec([-1,1,28,28])])\n",
    "losses_softmax = train(model_softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, datasets):\n",
    "    model.eval()\n",
    "\n",
    "    acc_set = list()\n",
    "    for batch_id, data in enumerate(datasets()):\n",
    "        images, labels = data\n",
    "        images = paddle.to_tensor(images)\n",
    "        labels = paddle.to_tensor(labels)\n",
    "        pred = model(images)   # 获取预测值\n",
    "        acc = paddle.metric.accuracy(input=pred, label=labels)\n",
    "        acc_set.extend(acc.numpy())\n",
    "    \n",
    "    # #计算多个batch的准确率\n",
    "    acc_val_mean = np.array(acc_set).mean()\n",
    "    return acc_val_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_of_softmax:0.7382563948631287\n"
     ]
    }
   ],
   "source": [
    "acc_of_softmax = evaluation(model_softmax, test_loader)\n",
    "print(f'acc_of_softmax:{acc_of_softmax}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
